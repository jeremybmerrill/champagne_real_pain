{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40e507a6-ba2a-461c-9694-730b0c7b88e1",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Champagne for my real friends\"\n",
    "subtitle: Real pain for my sham friends, real tricks for my meh friends, and finding more like this with NLP\n",
    "author: \n",
    " - name: \"Jeremy B. Merrill\"\n",
    "   url: https://www.jeremybmerrill.com\n",
    "date: today\n",
    "title-block-banner: true\n",
    "format: \n",
    "  html:\n",
    "    code-fold: true\n",
    "    toc: true\n",
    "toc-depth: 2\n",
    "jupyter: python3\n",
    "---\n",
    "\n",
    "What a catchy catchphrase. Someone [nerd-sniped me](https://xkcd.com/356/) in July, essentially daring me to find some more. Here we go. Let's trick the computer into coming up with more catchphrases like this.\n",
    "\n",
    "::: {.callout-note collapse=\"true\"}\n",
    "## Spoiler alert: a sample of the final output\n",
    "\n",
    "- metrics for my real friends, real tricks for my meh friends\n",
    "- focus for my real friends, real cuss for my faux friends\n",
    "- shamrocks for my real friends, real rocks for my sham friends\n",
    "- folkrock for my real friends, real crock for my faux friends\n",
    "- photos for my real friends, real toes for my faux friends\n",
    "- midrash for my real friends, real rash for my mid friends\n",
    "- medics for my real friends, real dicks for my meh friends\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753b4d7c",
   "metadata": {},
   "source": [
    "## But how do computers know how words sound?\n",
    "\n",
    "The [CMU Pronouncing Dictionary](www.speech.cs.cmu.edu/cgi-bin/cmudict) is a classical natural language processing resource that lists words and their pronunciations. It's thirty years old! It was compiled by human beings painstakingly listing each word's pronunciations -- no neural nets or artificial intelligence here.\n",
    "\n",
    "::: {.callout-tip collapse=\"true\"}\n",
    "## What is classical NLP? Why not use ChatGPT?\n",
    "\n",
    "So-called classical natural language processing relies on computational representations of the kinds of grammar concepts used by linguists. Think back to middle-school English class. You learned about nouns and verbs and how to diagram a sentence. Natural language processing analyzes language with those kinds of representations.\n",
    "\n",
    "This differs from AI-based NLP, whose representation of language tends to be more of black box. That black box representation is good for a lot of things, but it's famously terrible at computational humor.\n",
    "\n",
    "Here's what ChatGPT gave me when I asked it for _can you come up with some variants on the \"champagne for my real friends, real pain for my sham friends?\" template, but using different words than champagne, sham and pain?_.\n",
    "\n",
    "1. \"Laughter for my true friends, heartfelt tears for my false friends.\"\n",
    "2. \"Confetti for my loyal friends, bitter truth for my deceitful friends.\"\n",
    "3. \"Hugs for my genuine friends, icy distance for my deceptive friends.\"\n",
    "4. \"Sunshine for my authentic friends, thunderstorms for my treacherous friends.\"\n",
    "\n",
    "Those are terrible! They don't follow the template at all! We can do better with classical NLP.\n",
    "\n",
    "(But if you can coax better examples out of ChatGPT, let me know!)\n",
    ":::\n",
    "\n",
    "If we're gonna find more slogans like _champagne for my real friends, real pain for my sham friends_, we'll have to find words like _champagne_ that **sound** like compounds of a word like _sham_ and a word like _pain_ -- regardless of how they're spelled.\n",
    "\n",
    "Another example of what we're looking for is _focus for my real friends, real cuss for my faux friends_. In this example, _focus_ is our **champagne word**, and it's composed of _faux_ (a **sham word**) and _cuss_ (a **pain word**).\n",
    "\n",
    "Look below to see what the pronunciation of _champagne_ looks like, and how it's made up of the pronunciations of _sham_ and _pain_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45e0a43e-042e-4be9-a69a-77bd631e1c9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pronunciation of champagne is [['SH', 'AE0', 'M', 'P', 'EY1', 'N']]\n",
      "pronunciation of sham is [['SH', 'AE1', 'M']]\n",
      "pronunciation of pain is [['P', 'EY1', 'N']]\n"
     ]
    }
   ],
   "source": [
    "!pip install --disable-pip-version-check -q cmudict # install cmudict\n",
    "import cmudict\n",
    "cmudict_dict = cmudict.dict()\n",
    "\n",
    "for word in [\"champagne\", \"sham\", \"pain\"]:\n",
    "    print(\"pronunciation of {} is {}\".format(word, cmudict_dict[word]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735c3a34",
   "metadata": {},
   "source": [
    "In sum, we're looking for a **sham word** and a **pain word** that are both negative, but when combined, make a positive **champagne word**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033e046f-e6f2-48f6-b633-5dc16a808e8f",
   "metadata": {},
   "source": [
    "## Cleaning up the pronunciations\n",
    "\n",
    "The pronunciations in our example up there almost match.\n",
    "\n",
    "```\n",
    "champagne: [['SH', 'AE0', 'M', 'P', 'EY1', 'N']]\n",
    "sham:      [['SH', 'AE1', 'M']]\n",
    "pain:                        [['P', 'EY1', 'N']]\n",
    "```\n",
    "\n",
    "But not quite. The problem is that the vowel in _sham_ (`AE1`) isn't quite the same as the first vowel in _champagne_ (`AE0`). The numbers represent stress. `1` is primary stress; `2` is secondary, and `0` is no stress. We don't really care about stress for our joke format, so we will \"clean\" the data to ignore stress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f6a2dc5-ef0f-45e7-9254-ad92fd80d2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| echo: true\n",
    "#| code-fold: true\n",
    "#| code-summary: \"def remove_stress(phon):\"\n",
    "\n",
    "def remove_stress(phon):\n",
    "    return ''.join(i for i in phon if not i.isdigit())\n",
    "\n",
    "def clean_phonemes(pron):\n",
    "    pron = tuple(remove_stress(phon) for phon in pron) # remove stress        \n",
    "    return pron\n",
    "\n",
    "# map nouns to their \"cleaned\" pronunciations\n",
    "word_pronunciations = {}\n",
    "for word, prons in cmudict_dict.items():\n",
    "    word_pronunciations[word] = [clean_phonemes(pron) for pron in prons]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0523fdd-cf59-42d6-98c0-670cc5edaa3a",
   "metadata": {},
   "source": [
    "## A first try\n",
    "\n",
    "Let's use \"faux\" as our sham word. So we're looking for phrases like _faux pain for my real friends, real pain for my faux friends_... except where _faux pain_ is a real word.\n",
    "\n",
    "Let's find our champagne words, but starting with the sound \"faux\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cbd7fcb9-741e-48f5-9f13-9a3fb63bda88",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| echo: false\n",
    "#| code-fold: false\n",
    "\n",
    "SHAM_WORD = \"faux\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0fa982c4-1403-4fd2-a2f1-6887ed0aef88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are words (our candidate champagne words) that start with ('F', 'OW')\n",
      " - faucette: [('F', 'OW', 'S', 'EH', 'T')]\n",
      " - faucheux: [('F', 'OW', 'SH', 'OW')]\n",
      " - faupel: [('F', 'OW', 'P', 'EH', 'L')]\n",
      " - fauteux: [('F', 'OW', 'T', 'OW')]\n",
      " - foal: [('F', 'OW', 'L')]\n",
      " - foale: [('F', 'OW', 'L')]\n",
      " - foale's: [('F', 'OW', 'L', 'Z')]\n",
      " - foaling: [('F', 'OW', 'L', 'IH', 'NG')]\n",
      " - foam: [('F', 'OW', 'M')]\n",
      " - foaming: [('F', 'OW', 'M', 'IH', 'NG')]\n",
      " - foams: [('F', 'OW', 'M', 'Z')]\n",
      " - foamy: [('F', 'OW', 'M', 'IY')]\n",
      " - fobel: [('F', 'OW', 'B', 'AH', 'L')]\n",
      " - fobel's: [('F', 'OW', 'B', 'AH', 'L', 'Z')]\n",
      " - fobes: [('F', 'OW', 'B', 'Z')]\n"
     ]
    }
   ],
   "source": [
    "#| code-summary: \"def find_candidate_champagne_words(word_prons):\"\n",
    "\n",
    "# Due to an error in the CMU pronouncing dictionary, we have to specify that _faux_ \n",
    "# is actually pronounced like _foe_. (Not like _fox_.)\n",
    "SHAM_WORD_OVERRIDE = \"foe\" # None or \"foe\" # in case the pronunciation of the TARGET_WORD is wrong, as it oddly is for \"faux\"\n",
    "SHAM_SYLLABLE = word_pronunciations[SHAM_WORD_OVERRIDE or SHAM_WORD][0]\n",
    "\n",
    "HOW_MANY_TO_SHOW = 15\n",
    "\n",
    "def find_candidate_champagne_words(word_prons, sham_syllable=SHAM_SYLLABLE):\n",
    "    \"\"\"\n",
    "    champagne words have to start with the same sounds as the cham word (but can't be identical, it has to be longer!)\n",
    "    \"\"\"\n",
    "    word, prons = word_prons # destructuring\n",
    "    return any([                                              # candidate words must:\n",
    "               pron[:len(sham_syllable)] == sham_syllable and # start with same sounds\n",
    "               pron != sham_syllable                          # but be different\n",
    "            for pron in prons])\n",
    "\n",
    "nouns_starting_with_sham_word = list(filter(find_candidate_champagne_words, word_pronunciations.items()))\n",
    "print(\"Here are words (our candidate champagne words) that start with {}\".format(SHAM_SYLLABLE))\n",
    "for noun, prons in nouns_starting_with_sham_word[:HOW_MANY_TO_SHOW]:\n",
    "    print(f\" - {noun}: {prons}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9b5621-ee03-4e21-82ec-2ac85d4950da",
   "metadata": {},
   "source": [
    "### Finding pain words\n",
    "\n",
    "For each of our candidate **champagne words** (_folklore_, _folder_, etc.), we're going to check and see if it contains a **pain word**. That is, we're asking if _klore_ or _lder_ are words -- even if they're spelled differently.\n",
    "\n",
    "We do this really naively, by looping through every pronunciation of every single word in the dictionary, to see if matches the second half of the pronunciation of our candidate **champagne word**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40a4f756-8495-42ad-b211-a4d7ba8c5dc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faucette for my real friends, real set for my faux friends\n",
      "faucette for my real friends, real sette for my faux friends\n",
      "faucheux for my real friends, real chau for my faux friends\n",
      "faucheux for my real friends, real schau for my faux friends\n",
      "faucheux for my real friends, real show for my faux friends\n",
      "faupel for my real friends, real pehl for my faux friends\n",
      "faupel for my real friends, real pell for my faux friends\n",
      "faupel for my real friends, real pelle for my faux friends\n",
      "fauteux for my real friends, real toe for my faux friends\n",
      "fauteux for my real friends, real tow for my faux friends\n",
      "fauteux for my real friends, real towe for my faux friends\n",
      "foal for my real friends, real ohl for my faux friends\n",
      "foal for my real friends, real ol' for my faux friends\n",
      "foal for my real friends, real ole for my faux friends\n",
      "foale for my real friends, real ohl for my faux friends\n",
      "... (extra examples hidden)\n"
     ]
    }
   ],
   "source": [
    "#| code-summary: \"{} for my real friends, real {} for my {} friends\"\n",
    "\n",
    "count_so_far = 0\n",
    "HOW_MANY_TO_SHOW = 15\n",
    "\n",
    "for candidate_word, candidate_prons in nouns_starting_with_sham_word:\n",
    "    for pron in candidate_prons:\n",
    "        for word, prons in word_pronunciations.items():\n",
    "            if (pron[len(SHAM_SYLLABLE):] in prons) or (pron[len(SHAM_SYLLABLE)-1:] in prons):\n",
    "                count_so_far += 1\n",
    "                if count_so_far <= HOW_MANY_TO_SHOW: \n",
    "                    print(\"{} for my real friends, real {} for my {} friends\".format(candidate_word, word, SHAM_WORD))\n",
    "if count_so_far > HOW_MANY_TO_SHOW:\n",
    "    print(\"... (extra examples hidden)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d56f3d5b-f012-47eb-97b7-fc5fca0e80e9",
   "metadata": {},
   "source": [
    "Very cool! Those are kind of right.\n",
    "\n",
    "_focusing for my real friends, real kissing for my faux friends_ has got a ring to it, but kind of has the wrong valence. Who wishes kisses on their faux friends?\n",
    "\n",
    "But let's look closer.\n",
    "\n",
    "- _foamy for my real friends, real me for my faux friends_\n",
    " \n",
    "This is kind of funny, but _foamy_ is an adjective. That means that the phrase doesn't make a lot of sense. Let's try to skip those.\n",
    "\n",
    "- _focus for my real friends, real cos for my faux friends_\n",
    "- _focus for my real friends, real kiss for my faux friends_\n",
    "- _focus for my real friends, real kos for my faux friends_\n",
    " \n",
    "\n",
    "Some of the proposals are doubled. And, _cos_ and _kos_ aren't words I've heard of, we should try to eliminate those.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8a69a1-5fb9-416c-b50c-cd2620ade66a",
   "metadata": {},
   "source": [
    "## Building a fancier version\n",
    "\n",
    "above, we noticed a few problems:\n",
    "\n",
    "- non-nouns\n",
    "- weird, very rare words\n",
    "- multiple pronunciations of the same sounds\n",
    "- overprecise vowel matches mean we miss some slant rhymes that should be ok."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d11760f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| echo: false\n",
    "import itertools\n",
    "\n",
    "from os import environ\n",
    "NSFW_WORDS_ALLOWED = environ.get(\"NSFW_WORDS_ALLOWED\")\n",
    "import base64\n",
    "\n",
    "# helper functions for masking NSFW terms.\n",
    "def mask_nsfw(string):\n",
    "    return base64.b64encode(string.encode()).decode()\n",
    "    \n",
    "def unmask_nsfw(b64string):\n",
    "    return base64.b64decode(b64string).decode()\n",
    "\n",
    "test_input_str = 'asdfasdf'\n",
    "assert unmask_nsfw(mask_nsfw(test_input_str)) == test_input_str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3480d658",
   "metadata": {},
   "source": [
    "### champagne and pain words have to be nouns\n",
    "\n",
    "Let's use Wordnet to filter just to words that are nouns.\n",
    "\n",
    "unfortunately this could cost us gems like \n",
    "\n",
    " - _folkrock for my real friends, real croc for my faux friends_\n",
    " - _chamonix for real friends, real money for my sham friends_\n",
    " - _midrash for my real friends, real rash for my mid friends_\n",
    " \n",
    "because _folkrock_, _chamonix_ and _midrash_ aren't in Wordnet. So we add them back here as special extra nouns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dbfca093",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| echo: false\n",
    "#| code-fold: true\n",
    "#| code-summary: \"EXTRA_PRONUNCIATIONS = [...]\"\n",
    "\n",
    "from nltk.corpus import wordnet\n",
    "from nltk import download as nltk_download; nltk_download('wordnet', quiet=True);\n",
    "\n",
    "EXTRA_NOUNS = [\"folkrock\", # best genre evar\n",
    "               \"chamonix\", # an area in France\n",
    "               'poo', # missing from wordnet :(\n",
    "              ]\n",
    "\n",
    "\n",
    "# add pronunciations for some words that are missing from CMU\n",
    "cmudict_pronunciations = cmudict.dict()\n",
    "EXTRA_PRONUNCIATIONS = {\n",
    "    'fomites': [cmudict_pronunciations['foe'][0] + cmudict_pronunciations['mites'][0]],\n",
    "    'fomite': [cmudict_pronunciations['foe'][0] + cmudict_pronunciations['mite'][0]],\n",
    "    'shamrocks': [cmudict_pronunciations['sham'][0] + cmudict_pronunciations['rocks'][0]],\n",
    "    'midrash': [cmudict_pronunciations['mid'][0] + ['R'] + cmudict_pronunciations['gash'][0][1:]],\n",
    "    'badges': [cmudict_pronunciations[\"bad\"][0] + cmudict_pronunciations['badges'][0][2:]],\n",
    "    'meh': [['M', 'EH1']]\n",
    "}\n",
    "if NSFW_WORDS_ALLOWED:\n",
    "    (unmask_nsfw('aml6eg=='), [cmudict_pronunciations['badges'][0][2:]]),\n",
    "\n",
    "for word, prons in EXTRA_PRONUNCIATIONS.items():\n",
    "    cmudict_pronunciations[word] += prons\n",
    "    \n",
    "EXTRA_NOUNS += EXTRA_PRONUNCIATIONS.keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "687388c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: true\n",
    "#| code-summary: \"def is_noun(word):\"\n",
    "\n",
    "def is_noun(word):\n",
    "    return any(synset.pos() for synset in wordnet.synsets(word, pos=wordnet.NOUN)) or word in EXTRA_NOUNS\n",
    "\n",
    "assert is_noun('mite')      # testing basic case\n",
    "assert is_noun('might')     # testing words that can be multiple PoS\n",
    "assert is_noun('shamrocks') # testing plurals\n",
    "assert is_noun('mites')     # testing plurals\n",
    "assert is_noun('poo')       # testing manual additions\n",
    "assert not is_noun('photographed')     # testing handling of inflected verbs\n",
    "assert not is_noun('focused')          # testing handling of inflected verbs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c0cbd7",
   "metadata": {},
   "source": [
    "### let's ignore very rare words\n",
    "\n",
    "First we download a list of word frequencies; we'll ignore anything that occurs less than 500,000 times in the corpus. Then, we download a list of nouns; we'll ignore anything that isn't a noun. (We add back a few nouns I like.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7fbddc7a-9c9f-4512-8645-648723a86b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: true\n",
    "#| code-summary: \"download file of the 1/3 million most frequent words, with counts\"\n",
    "\n",
    "# ignore words that occur less than this many times in the Google Web Trillion Word Corpus \n",
    "# many of these less-frequent words are very bizarre, but appear in the CMU Pronouncing Dictionary nevertheless.\n",
    "# the champagne and sham words can be rare, but they must be nouns.\n",
    "# the pain word must be a more common noun.\n",
    "\n",
    "# download file of \"The 1/3 million most frequent words, all lowercase, with counts\"\n",
    "!wget -nc --quiet https://norvig.com/ngrams/count_1w.txt\n",
    "import csv\n",
    "with open(\"count_1w.txt\") as f:\n",
    "    word_frequencies = dict([(row[0], int(row[1])) for row in csv.reader(f, delimiter=\"\\t\")])\n",
    "\n",
    "MIN_FREQUENCY = 100_000\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586c2d1c",
   "metadata": {},
   "source": [
    "### let's be a little more chill about vowels\n",
    "\n",
    "We also don't care about all the vowel distinctions that the dictionary uses. We'll implement \"vowel reductions\" that mirror some of the ways American English speakers can change vowels in fast or casual speech, so that near-identical words are okay.\n",
    "\n",
    "Also we ignore very uncommon words and non-nouns, which don't fit in the joke format."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ac3991",
   "metadata": {},
   "source": [
    "::: {.callout-tip collapse=\"true\"}\n",
    "## What are these vowels?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cf638b38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>example</th>\n",
       "      <th>pronunciation</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vowel</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AA</th>\n",
       "      <td>was</td>\n",
       "      <td>[W, AA1, Z]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AE</th>\n",
       "      <td>have</td>\n",
       "      <td>[HH, AE1, V]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AH</th>\n",
       "      <td>one</td>\n",
       "      <td>[W, AH1, N]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AO</th>\n",
       "      <td>law</td>\n",
       "      <td>[L, AO1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AW</th>\n",
       "      <td>out</td>\n",
       "      <td>[AW1, T]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AY</th>\n",
       "      <td>time</td>\n",
       "      <td>[T, AY1, M]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EH</th>\n",
       "      <td>web</td>\n",
       "      <td>[W, EH1, B]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ER</th>\n",
       "      <td>first</td>\n",
       "      <td>[F, ER1, S, T]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EY</th>\n",
       "      <td>page</td>\n",
       "      <td>[P, EY1, JH]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IH</th>\n",
       "      <td>will</td>\n",
       "      <td>[W, IH1, L]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IY</th>\n",
       "      <td>see</td>\n",
       "      <td>[S, IY1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OW</th>\n",
       "      <td>home</td>\n",
       "      <td>[HH, OW1, M]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OY</th>\n",
       "      <td>point</td>\n",
       "      <td>[P, OY1, N, T]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UH</th>\n",
       "      <td>good</td>\n",
       "      <td>[G, UH1, D]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UW</th>\n",
       "      <td>news</td>\n",
       "      <td>[N, UW1, Z]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      example   pronunciation\n",
       "vowel                        \n",
       "AA        was     [W, AA1, Z]\n",
       "AE       have    [HH, AE1, V]\n",
       "AH        one     [W, AH1, N]\n",
       "AO        law        [L, AO1]\n",
       "AW        out        [AW1, T]\n",
       "AY       time     [T, AY1, M]\n",
       "EH        web     [W, EH1, B]\n",
       "ER      first  [F, ER1, S, T]\n",
       "EY       page    [P, EY1, JH]\n",
       "IH       will     [W, IH1, L]\n",
       "IY        see        [S, IY1]\n",
       "OW       home    [HH, OW1, M]\n",
       "OY      point  [P, OY1, N, T]\n",
       "UH       good     [G, UH1, D]\n",
       "UW       news     [N, UW1, Z]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| echo: true\n",
    "#| code-fold: true\n",
    "#| code-summary: finding examples of each vowel, so we can find which vowels to combine\n",
    "\n",
    "try:\n",
    "    import pandas as pd\n",
    "    has_pandas = True\n",
    "except:\n",
    "    has_pandas = False\n",
    "    \n",
    "vowels = [ph for ph, types in cmudict.phones() if types[0] == 'vowel']\n",
    "vowel_examples = []\n",
    "for vowel in vowels:\n",
    "    for word, prons in sorted(cmudict_dict.items(), key=lambda word_prons: -word_frequencies.get(word_prons[0], 0)):\n",
    "        if \"'\" in word or '.' in word: continue\n",
    "        if not is_noun(word): continue\n",
    "        if 'R' in prons[0]: continue\n",
    "        if len(word) < 3 or len(word) >= 6: continue\n",
    "\n",
    "        if vowel in clean_phonemes(prons[0]):\n",
    "            vowel_examples.append((vowel, word, prons[0]))\n",
    "            break\n",
    "if has_pandas:\n",
    "    display(pd.DataFrame(vowel_examples, columns=[\"vowel\", \"example\", \"pronunciation\"]).set_index('vowel'))\n",
    "else:\n",
    "    for vowel, example, pron in vowel_examples:\n",
    "        print(vowel, example, pronunciation)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e815a8-f53c-4959-91e6-d6b3ab599836",
   "metadata": {},
   "source": [
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ca0cea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| echo: true\n",
    "#| code-fold: true\n",
    "#| code-summary: \"def reduce_phonemes(pron):\"\n",
    "\n",
    "VOWEL_REDUCTIONS = {\n",
    "    \"AH\": \"AH\", \"AA\": \"AH\", \"AO\": \"AH\", \"UH\": \"AH\", \"IH\": \"AH\", \"EH\": \"AH\", \n",
    "    \"OW\": \"AH\" # special for chamonix / money\n",
    "}\n",
    "\n",
    "VOWEL_STRICTNESS = 2\n",
    "# 1 = least; compare only first char of vowel symbol \n",
    "# 2 = medium; perform some vowel reductions\n",
    "# 3 = most; compare vowels as is (with stress removed)\n",
    "\n",
    "def is_vowel(phon):\n",
    "    return phones_dict[remove_stress(phon)][0] == 'vowel'\n",
    "\n",
    "phones_dict = dict(cmudict.phones())\n",
    "def reduce_phonemes(pron, vowel_strictness=VOWEL_STRICTNESS):\n",
    "    if vowel_strictness < 3:\n",
    "        pron = [(phon[0] if (vowel_strictness == 1) else VOWEL_REDUCTIONS.get(remove_stress(phon), phon)) if is_vowel(phon) else phon for phon in pron]\n",
    "    pron = clean_phonemes(pron) # remove stress        \n",
    "    return pron\n",
    "    \n",
    "# `assert` lines are tests to make sure I didn't F it up.\n",
    "print(\"pronunciation of 'ruck', as is    {}\"  .format(          tuple(cmudict_dict[\"ruck\"][0])))\n",
    "print(\"pronunciation of 'ruck', cleaned  {}\".format( reduce_phonemes(cmudict_dict[\"ruck\"][0], vowel_strictness=2)))\n",
    "assert reduce_phonemes(cmudict.dict()[\"ruck\"][0], vowel_strictness=2)[1] == \"AH\"\n",
    "\n",
    "print(\"pronunciation of 'wreck', as is   {}\"  .format(          tuple(cmudict_dict[\"wreck\"][0])))\n",
    "print(\"pronunciation of 'wreck', cleaned {}\".format( reduce_phonemes(cmudict_dict[\"wreck\"][0], vowel_strictness=2)))\n",
    "assert reduce_phonemes(cmudict.dict()[\"wreck\"][0], vowel_strictness=2)[1] == \"AH\"\n",
    "\n",
    "assert reduce_phonemes(cmudict.dict()[\"ruck\"][0], vowel_strictness=1)[1] == \"A\"\n",
    "assert reduce_phonemes(cmudict.dict()[\"wreck\"][0], vowel_strictness=1)[1] == \"E\"\n",
    "\n",
    "assert reduce_phonemes(cmudict.dict()[\"ruck\"][0], vowel_strictness=3)[1] == \"AH\"\n",
    "assert reduce_phonemes(cmudict.dict()[\"wreck\"][0], vowel_strictness=3)[1] == \"EH\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1ef70fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| echo: false\n",
    "#| code-fold: true\n",
    "\n",
    "# map nouns to their \"cleaned\" pronunciations\n",
    "\n",
    "# champagne words are allowed to be uncommon.\n",
    "strict_noun_pronunciations = {} # the sham word has to exactly match the start of the champagne word, because \n",
    "                                # the joke format relies on ambiguity between \"champagne\" and \"sham pain\".\n",
    "\n",
    "strict_word_pronunciations = {} # candidate sham words (which are adjectives, not nouns) and can be uncommon.\n",
    "\n",
    "# but pain words have to be common.\n",
    "strict_common_noun_pronunciations = {}\n",
    "reduced_common_noun_pronunciations = {} # the pain word can match a reduced pronunciation of the back half of the\n",
    "                                        # champagne word.\n",
    "for word, prons in cmudict_pronunciations.items():\n",
    "    strict_word_pronunciations[word] = [reduce_phonemes(pron, vowel_strictness=3) for pron in prons]\n",
    "    if is_noun(word): \n",
    "        strict_noun_pronunciations[word] = [reduce_phonemes(pron, vowel_strictness=3) for pron in prons]\n",
    "        if word_frequencies.get(word, 0) > MIN_FREQUENCY or word in EXTRA_NOUNS:\n",
    "            reduced_common_noun_pronunciations[word] = [reduce_phonemes(pron) for pron in prons]\n",
    "            strict_common_noun_pronunciations[word]  = [reduce_phonemes(pron, vowel_strictness=3) for pron in prons]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2e9f37bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| echo: true\n",
    "#| code-fold: true\n",
    "#| code-summary: \"def get_best_pain_word(champagne_prons, sham_syllable):\"\n",
    "\n",
    "def get_best_pain_word(champagne_prons, sham_syllable, quiet=True):\n",
    "    \"\"\"\n",
    "    find the most common word that matches the back half of the champagne word\n",
    "    if we can't find one, find one that matches the back half of the champagne word, \n",
    "        but repeating the last phoneme of the sham word \n",
    "        (e.g. chamonix for my real friends, real money for my sham friends)\n",
    "        this is \"gemination\" -- we double up the \n",
    "    if we still can't find one, try with reduced pronunciations\n",
    "    \"\"\"\n",
    "\n",
    "    # this lets us prefer better vowel matches to worse ones, i.e.\n",
    "    # ok: folkrock for my real friends, real crook for my faux friends\n",
    "    # better: folkrock for my real friends, real croc for my faux friends\n",
    "    # previously it prefers \"crook\" because crook is more common than croc\n",
    "\n",
    "    # this also lets us prefer ungeminated matches over geminated ones\n",
    "    \n",
    "    for champagne_pron in champagne_prons:\n",
    "        if sham_syllable != champagne_pron[:len(sham_syllable)] and \\\n",
    "           reduce_phonemes(sham_syllable, vowel_strictness=2) != champagne_pron[:len(sham_syllable)]: \n",
    "            # print(\"{} doesn't match {}, skipping\".format(sham_syllable, champagne_pron)) # just for debug.\n",
    "            continue\n",
    "        for (pronunciations, syllable_offset), score in zip(list(itertools.product(\n",
    "            [strict_common_noun_pronunciations, reduced_common_noun_pronunciations], \n",
    "            [0, 1])\n",
    "                                                   ), range(4, 0, -1)):\n",
    "            # gemination is only allowed for consonant-final sham words.\n",
    "            # \"photograph for my real friends, real autograph for my faux friends\" should be invalid\n",
    "            if syllable_offset == 1 and is_vowel(sham_syllable[-1]): continue\n",
    "                \n",
    "            for pain_word, pain_prons in sorted(pronunciations.items(), key=lambda word_prons: -word_frequencies.get(word[0], 0)):\n",
    "                if (champagne_pron[len(sham_syllable)-syllable_offset:] in pain_prons):\n",
    "                    return pain_word, score\n",
    "    return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "acee7b12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folkrock for my real friends, real crock for my faux friends\n",
      "fomite for my real friends, real might for my faux friends\n",
      "photo for my real friends, real toe for my faux friends\n",
      "foam for my real friends, real mm for my faux friends\n",
      "phobos for my real friends, real bus for my faux friends\n",
      "fomites for my real friends, real mites for my faux friends\n",
      "focuses for my real friends, real kisses for my faux friends\n",
      "focus for my real friends, real cus for my faux friends\n",
      "phony for my real friends, real knee for my faux friends\n",
      "focusing for my real friends, real kissing for my faux friends\n",
      "photos for my real friends, real toes for my faux friends\n",
      "phoney for my real friends, real knee for my faux friends\n",
      "focus for my real friends, real kis for my faux friends\n",
      "photons for my real friends, real tonnes for my faux friends\n",
      "photon for my real friends, real ton for my faux friends\n",
      "folio for my real friends, real leo for my faux friends\n",
      "foliage for my real friends, real ledge for my faux friends\n",
      "focuses for my real friends, real kisses for my faux friends\n",
      "folklore for my real friends, real clear for my faux friends\n",
      "focusing for my real friends, real kissing for my faux friends\n"
     ]
    }
   ],
   "source": [
    "#| code-summary: \"def find_champagne_real_pain_phrases('faux'):\"\n",
    "\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "def find_champagne_real_pain_phrases(sham_word, sham_word_override=None, real_word=\"real\", quiet=True):\n",
    "    # sham syllables can be any PoS and need to have the extras added.\n",
    "    # e.g. \"mid\" and \"faux\" are adjectives; \"meh\" isn't in the CMU pron dictionary.\n",
    "    sham_syllable = strict_word_pronunciations[sham_word_override or sham_word][0]\n",
    "    \n",
    "    nouns_starting_with_sham_word = list(filter(\n",
    "        lambda candidate_word: find_candidate_champagne_words(candidate_word, sham_syllable=sham_syllable), \n",
    "        strict_noun_pronunciations.items()\n",
    "    ))\n",
    "    if not quiet:\n",
    "        print(\"Here are words (our candidate champagne words) that start with {}\".format(sham_syllable))\n",
    "        for noun, prons in nouns_starting_with_sham_word:\n",
    "            print(f\" - {noun}: {prons}\")\n",
    "    champagne_pain_pairs = set()\n",
    "    for candidate_champagne_word, _ in nouns_starting_with_sham_word:\n",
    "        for candidate_champagne_prons in zip(strict_common_noun_pronunciations.get(candidate_champagne_word, []), \n",
    "                reduced_common_noun_pronunciations.get(candidate_champagne_word, [])):\n",
    "            best_pain_word, score = get_best_pain_word(candidate_champagne_prons, sham_syllable)\n",
    "            if best_pain_word:\n",
    "                champagne_pain_pairs.add((candidate_champagne_word, best_pain_word, score))    \n",
    "        \n",
    "    return [(f\"{candidate_champagne_word} for my {real_word} friends, {real_word} {pain_word} for my {sham_word} friends\"),\n",
    "            {\"candidate_champagne_word\": candidate_champagne_word, \"real_word\": real_word, \"pain_word\": pain_word, \"sham_word\": sham_word, \"score\": score})\n",
    "            for candidate_champagne_word, pain_word, score in sorted(champagne_pain_pairs, key=lambda x: -x[2])]\n",
    "\n",
    "for champagne_phrase, _ in find_champagne_real_pain_phrases(SHAM_WORD, sham_word_override=SHAM_WORD_OVERRIDE):\n",
    "    print(champagne_phrase)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b611f60e",
   "metadata": {},
   "source": [
    "## A worked example\n",
    "\n",
    "Let's walk through this step by step.\n",
    "\n",
    "Chamonix is a province in France. It has two very different pronunciations in the CMU Pronouncing Dictionary. One Americanized pronunciation, _tcham-onyx_ and a French one like _sham-oh-knee_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a3d66aae-0345-499e-bfc5-04d70135c047",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['CH', 'AE1', 'M', 'AH0', 'N', 'IH0', 'K', 'S'],\n",
       " ['SH', 'AE0', 'M', 'OW0', 'N', 'IY0']]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| code-fold: false\n",
    "\n",
    "cmudict.dict()[\"chamonix\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c3997e",
   "metadata": {},
   "source": [
    "Here's what the pronunciation looks like with the stresses removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6cb1d93c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('CH', 'AE', 'M', 'AH', 'N', 'IH', 'K', 'S'),\n",
       " ('SH', 'AE', 'M', 'OW', 'N', 'IY')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| code-fold: false\n",
    "\n",
    "strict_word_pronunciations[\"chamonix\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4f20c22c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('SH', 'AE', 'M')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| code-fold: false\n",
    "\n",
    "sham_word = \"sham\"\n",
    "sham_syllable = strict_word_pronunciations[sham_word][0]\n",
    "sham_syllable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de817cf7",
   "metadata": {},
   "source": [
    "See how `('SH', 'AE', 'M')` is the first half of the second pronunciation, `('SH', 'AE', 'M', 'OW', 'N', 'IY')`\n",
    "\n",
    "Now, we're looking to see if there are any _pain words_ that are pronounced like any of these options for the pronunciation of the back half of _chamonix_.\n",
    "\n",
    "First, we're looking for something that matches `('OW', 'N', 'IY')` or `('M', 'OW', 'N', 'IY')` -- the back half without any vowel reductions. `('OW', 'N', 'IY')` would be preferable, since it doesn't require double-up the `M` in both the sham word (_sham_) and the pain word (_money_, in this case).\n",
    "\n",
    "Here are those strict pronunciations that we're looking for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6f437de8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('AH', 'N', 'IH', 'K', 'S')\n",
      "('M', 'AH', 'N', 'IH', 'K', 'S')\n",
      "('OW', 'N', 'IY')\n",
      "('M', 'OW', 'N', 'IY')\n"
     ]
    }
   ],
   "source": [
    "#| code-fold: false\n",
    "\n",
    "for chamonix_pronunciation in strict_word_pronunciations[\"chamonix\"]:\n",
    "    print(chamonix_pronunciation[len(sham_syllable):])\n",
    "    print(chamonix_pronunciation[len(sham_syllable)-1:])    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c786b03",
   "metadata": {},
   "source": [
    "Or, if we can't find something that matches the strict, we'd look for something that matches the back half of _chamonix_ with reductions.\n",
    "\n",
    "Here's what those reduced pronunciations look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7608e2be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('AH', 'N', 'AH', 'K', 'S')\n",
      "('M', 'AH', 'N', 'AH', 'K', 'S')\n",
      "('AH', 'N', 'IY')\n",
      "('M', 'AH', 'N', 'IY')\n"
     ]
    }
   ],
   "source": [
    "#| code-fold: false\n",
    "\n",
    "for chamonix_pronunciation in reduced_common_noun_pronunciations[\"chamonix\"]:\n",
    "    print(chamonix_pronunciation[len(sham_syllable):])\n",
    "    print(chamonix_pronunciation[len(sham_syllable)-1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21786dac",
   "metadata": {},
   "source": [
    "With those eight acceptable pronunciations in mind, we loop through every noun in the English language, to see if any nouns are pronounced that way. We find three!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d0c65422-bb66-4083-b44c-f3c55e4bb40f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('M', 'AH', 'N', 'IY')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| code-fold: false\n",
    "\n",
    "strict_noun_pronunciations[\"money\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "71af1f9a-ea69-42d8-877a-0ce1d4e1528c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('AA', 'N', 'IH', 'K', 'S')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| code-fold: false\n",
    "\n",
    "strict_noun_pronunciations[\"onyx\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b60c27fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('AE', 'N', 'EH', 'K', 'S'), ('AH', 'N', 'EH', 'K', 'S')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| code-fold: false\n",
    "\n",
    "strict_noun_pronunciations[\"annex\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3234509",
   "metadata": {},
   "source": [
    "None of those three words match either strict pronunciation of _chamonix_. So we get no result from `get_best_pain_word` here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "71e6d9fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| code-fold: false\n",
    "\n",
    "get_best_pain_word(strict_noun_pronunciations[\"chamonix\"], strict_noun_pronunciations[\"sham\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef685ae2",
   "metadata": {},
   "source": [
    "But they do match the reduced pronunciation of _chamonix_. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ab218890",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('money', 3)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| code-fold: false\n",
    "\n",
    "get_best_pain_word(reduced_common_noun_pronunciations[\"chamonix\"], strict_noun_pronunciations[\"sham\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34635fda",
   "metadata": {},
   "source": [
    "_Money_ is picked becuase it is the more common than either _onyx_ or _annex_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7a10ee18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frequency of money is 190,205,072\n",
      "frequency of  onyx is 2,315,135\n",
      "frequency of annex is 8,465,905\n"
     ]
    }
   ],
   "source": [
    "#| code-fold: false\n",
    "\n",
    "for word in [\"money\", \"onyx\", \"annex\"]:\n",
    "    print(\"frequency of {: >5} is {:,.0f}\".format(word, word_frequencies[word]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a25d21",
   "metadata": {},
   "source": [
    "## Sham Friends, Mid Friends, Meh Friends and Bad Friends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e569da88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are words (our candidate champagne words) that start with ('SH', 'AE', 'M')\n",
      " - chamonix: [('CH', 'AE', 'M', 'AH', 'N', 'IH', 'K', 'S'), ('SH', 'AE', 'M', 'OW', 'N', 'IY')]\n",
      " - champagne: [('SH', 'AE', 'M', 'P', 'EY', 'N')]\n",
      " - champagnes: [('SH', 'AE', 'M', 'P', 'EY', 'N', 'Z')]\n",
      " - champlain: [('SH', 'AE', 'M', 'P', 'L', 'EY', 'N')]\n",
      " - shamble: [('SH', 'AE', 'M', 'B', 'AH', 'L')]\n",
      " - shambles: [('SH', 'AE', 'M', 'B', 'AH', 'L', 'Z')]\n",
      " - shampoo: [('SH', 'AE', 'M', 'P', 'UW')]\n",
      " - shampoos: [('SH', 'AE', 'M', 'P', 'UW', 'Z')]\n",
      " - shamrock: [('SH', 'AE', 'M', 'R', 'AA', 'K')]\n",
      " - shamrocks: [('SH', 'AE', 'M', 'R', 'AA', 'K', 'S')]\n",
      "champlain for my real friends, real plain for my sham friends\n",
      "shamrock for my real friends, real roc for my sham friends\n",
      "champagnes for my real friends, real pains for my sham friends\n",
      "shamrocks for my real friends, real rocks for my sham friends\n",
      "shampoo for my real friends, real poo for my sham friends\n",
      "champagne for my real friends, real pain for my sham friends\n",
      "chamonix for my real friends, real money for my sham friends\n",
      "shambles for my real friends, real balls for my sham friends\n"
     ]
    }
   ],
   "source": [
    "for champagne_phrase, _ in find_champagne_real_pain_phrases(\"sham\", quiet=False):\n",
    "    print(champagne_phrase)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2d7af882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "midrash for my real friends, real rash for my mid friends\n",
      "midlands for my real friends, real lands for my mid friends\n",
      "midwife for my real friends, real wife for my mid friends\n",
      "midway for my real friends, real way for my mid friends\n",
      "midsummer for my real friends, real summer for my mid friends\n",
      "midland for my real friends, real land for my mid friends\n",
      "midstream for my real friends, real stream for my mid friends\n",
      "mideast for my real friends, real east for my mid friends\n",
      "midair for my real friends, real air for my mid friends\n",
      "midpoint for my real friends, real point for my mid friends\n",
      "midnight for my real friends, real knight for my mid friends\n",
      "midweek for my real friends, real week for my mid friends\n",
      "midwives for my real friends, real wives for my mid friends\n",
      "middling for my real friends, real ling for my mid friends\n",
      "midwinter for my real friends, real winter for my mid friends\n",
      "midline for my real friends, real line for my mid friends\n",
      "midterm for my real friends, real term for my mid friends\n",
      "midwest for my real friends, real west for my mid friends\n",
      "midday for my real friends, real day for my mid friends\n",
      "midterms for my real friends, real terms for my mid friends\n",
      "middle for my real friends, real el for my mid friends\n",
      "medulla for my real friends, real allah for my mid friends\n",
      "middleton for my real friends, real dalton for my mid friends\n",
      "medellin for my real friends, real dylan for my mid friends\n"
     ]
    }
   ],
   "source": [
    "for champagne_phrase, _ in find_champagne_real_pain_phrases(\"mid\"):\n",
    "    print(champagne_phrase)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3d4697ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "badlands for my real friends, real lands for my bad friends\n",
      "badness for my real friends, real nes for my bad friends\n",
      "badges for my real friends, real jaws for my bad friends\n"
     ]
    }
   ],
   "source": [
    "for champagne_phrase, _ in find_champagne_real_pain_phrases(\"bad\"):\n",
    "    print(champagne_phrase)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "046ebd66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric for my real friends, real trick for my meh friends\n",
      "meadows for my real friends, real doze for my meh friends\n",
      "memory for my real friends, real murray for my meh friends\n",
      "merits for my real friends, real ruts for my meh friends\n",
      "marriage for my real friends, real ridge for my meh friends\n",
      "medic for my real friends, real dick for my meh friends\n",
      "medics for my real friends, real dicks for my meh friends\n",
      "messes for my real friends, real says for my meh friends\n",
      "method for my real friends, real thud for my meh friends\n",
      "marrow for my real friends, real rho for my meh friends\n",
      "merit for my real friends, real rut for my meh friends\n",
      "merits for my real friends, real ritz for my meh friends\n",
      "mary for my real friends, real re for my meh friends\n",
      "mesquite for my real friends, real skeet for my meh friends\n",
      "melange for my real friends, real lange for my meh friends\n",
      "memo for my real friends, real mo for my meh friends\n",
      "married for my real friends, real read for my meh friends\n",
      "menus for my real friends, real news for my meh friends\n",
      "marriages for my real friends, real ridges for my meh friends\n",
      "methane for my real friends, real thane for my meh friends\n",
      "mecca for my real friends, real ca for my meh friends\n",
      "medici for my real friends, real dc for my meh friends\n",
      "maris for my real friends, real rus for my meh friends\n",
      "meadow for my real friends, real doe for my meh friends\n",
      "mariner for my real friends, real runner for my meh friends\n",
      "metrics for my real friends, real tricks for my meh friends\n",
      "mariners for my real friends, real runners for my meh friends\n",
      "melia for my real friends, real leo for my meh friends\n",
      "mettle for my real friends, real tall for my meh friends\n",
      "metals for my real friends, real tells for my meh friends\n",
      "medicare for my real friends, real dakar for my meh friends\n",
      "memos for my real friends, real mas for my meh friends\n",
      "melanin for my real friends, real lenin for my meh friends\n",
      "medico for my real friends, real deco for my meh friends\n",
      "metal for my real friends, real tall for my meh friends\n",
      "mellon for my real friends, real lawn for my meh friends\n",
      "melons for my real friends, real lawns for my meh friends\n",
      "menace for my real friends, real nes for my meh friends\n",
      "medals for my real friends, real dolls for my meh friends\n",
      "message for my real friends, real sedge for my meh friends\n",
      "melon for my real friends, real lawn for my meh friends\n",
      "medicaid for my real friends, real decade for my meh friends\n",
      "medicine for my real friends, real dawson for my meh friends\n",
      "medal for my real friends, real dahl for my meh friends\n",
      "mete for my real friends, real ta for my meh friends\n",
      "metis for my real friends, real tess for my meh friends\n",
      "meshes for my real friends, real shows for my meh friends\n"
     ]
    }
   ],
   "source": [
    "for champagne_phrase, _ in find_champagne_real_pain_phrases(\"meh\"):\n",
    "    print(champagne_phrase)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f341ea30",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Future enhancements\n",
    "\n",
    "### make sure that the pain word has a negative valence\n",
    "\n",
    "There are two ways to do this:\n",
    "\n",
    " - [dictionary-based sentiment analysis methodologies](https://nealcaren.org/lessons/wordlists/) like VADER or AFINN.\n",
    " - asking GPT4.\n",
    " \n",
    "The benefit of this would be to exclude phrases like:\n",
    " \n",
    "- _fomite for my real friends, real might for my faux friends_\n",
    "\n",
    "which is not a very good phrase, because we're wishing something bad on our real friends, and something good on our faux friends. That's the opposite of what we want.\n",
    "\n",
    "- _fomites for my real friends, real mites for my faux friends_\n",
    "\n",
    "is better because \"mites\" are bad. It's still not ideal, since \"fomites\" are bad, and we're wishing infection-carrying objects on our friends.\n",
    "\n",
    "This sentiment/valence rating could be used instead of frequency to decide which pain word to use. Right now, for \"folkrock\", we generate _\"folkrock for my real friends, real crock for my faux friends\"_. This is not ideal because \"crock\" has only a very vague negative valence (implicitly it's a _crock of shit_, I guess). It would be better if it was \"croc\" instead as the pain word -- because it's mean to wish a crocodile on someone.\n",
    "\n",
    "The code below is a first stab at the dictionary-based sentiment analysis methodology, excluding any output where the **pain word** isn't negative, according to the [VADER sentiment analysis tool](https://github.com/cjhutto/vaderSentiment). But the VADER lexicon list is relatively small, and _mites_ isn't on it, so many good phrases get incorrectly excluded. (Another sentiment wordlist, [AFINN](https://github.com/fnielsen/afinn), only contains pain words already present in VADER.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "338150f8-c0b7-4603-9849-02435129fba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric for my real friends, real trick for my meh friends\n",
      "medic for my real friends, real dick for my meh friends\n",
      "metrics for my real friends, real tricks for my meh friends\n",
      "champagnes for my real friends, real pains for my sham friends\n",
      "champagne for my real friends, real pain for my sham friends\n",
      "midrash for my real friends, real rash for my mid friends\n"
     ]
    }
   ],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "nltk_download('vader_lexicon', quiet=True)\n",
    "s = SentimentIntensityAnalyzer()\n",
    "\n",
    "overrides = {\"faux\": \"foe\"}\n",
    "for sham_word in [\"meh\", \"sham\", \"faux\", \"bad\", \"mid\"]:\n",
    "    for champagne_phrase, metadata in find_champagne_real_pain_phrases(sham_word, sham_word_override=overrides.get(sham_word)):\n",
    "        if s.lexicon.get(metadata[\"pain_word\"], 0) < 0:\n",
    "            print(champagne_phrase)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3016c53e",
   "metadata": {},
   "source": [
    "### use \"a\" for singular pain words\n",
    "\n",
    "for singular, count nouns, we should add \"a\" (or \"an\") before hand, so it makes a bit more sense.\n",
    "\n",
    "- _**a** phoney for my real friends, **a** real knee for my faux friends_\n",
    "\n",
    "this would be tricky, because we don't want to do this for count nouns (like _champagne_). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0712fbba",
   "metadata": {},
   "source": [
    "### metrics for my real friends\n",
    "\n",
    "compile all the examples here and get some humans to rate them on how funny they are, and see if we can't figure out some more rules to filter out the crappy ones and generate more funny ones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa46f7e",
   "metadata": {},
   "source": [
    "### better phonology\n",
    "\n",
    "The vowel reduction logic above is pretty rough. My linguistics education is rusty enough that I can't write a rule to exclude false-positive matches like _medulla for my real friends, real allah for my mid friends_.\n",
    "\n",
    "Additionally, diphthongs are often close enough to single vowels to count as a rhyme. You could imagine _Champlain for my real friends, real playin' for my sham friends_ working, but the code as of now wouldn't be able to equate _plain_ and _playin'_. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6be2bfcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| echo: true\n",
    "#| code-fold: true\n",
    "#| code-summary: regression testing\n",
    "\n",
    "# regression testing\n",
    "assert not any(['photograph' in phrase and 'autograph' in phrase for phrase in find_champagne_real_pain_phrases(\"faux\", sham_word_override=\"foe\")])\n",
    "assert any(['shamrocks' in phrase for phrase in find_champagne_real_pain_phrases(\"sham\")])\n",
    "assert any(['money' in phrase and 'chamonix' in phrase for phrase in find_champagne_real_pain_phrases(\"sham\")])\n",
    "assert any(['midrash' in phrase for phrase in find_champagne_real_pain_phrases(\"mid\")])\n",
    "assert any(['folkrock' in phrase for phrase in find_champagne_real_pain_phrases(\"faux\", sham_word_override=\"foe\")])\n",
    "assert any(['fomites' in phrase for phrase in find_champagne_real_pain_phrases(\"faux\", sham_word_override=\"foe\")])\n",
    "if NSFW_WORDS_ALLOWED:\n",
    "    assert any(['badges' in phrase and unmask_nsfw('aml6eg==') in phrase for phrase in find_champagne_real_pain_phrases(\"bad\")])\n",
    "else:\n",
    "    assert not any(['badges' in phrase and unmask_nsfw('aml6eg==') in phrase for phrase in find_champagne_real_pain_phrases(\"bad\")])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6526f0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| echo: true\n",
    "#| code-fold: true\n",
    "#| code-summary: debugging why a word didn't show up.\n",
    "\n",
    "\n",
    "# debugging:\n",
    "def why_is_this_word_absent(word):\n",
    "    if not is_noun(word):\n",
    "        print(f\"is_noun({word}) is false\")\n",
    "    if word in word_frequencies and word_frequencies.get(word) < MIN_FREQUENCY:\n",
    "        print(\"{}'s frequency is {}, which is below MIN_FREQUENCY\".format(word, word_frequencies.get(word), MIN_FREQUENCY))\n",
    "    if word not in word_frequencies:\n",
    "        print(f\"{word} not in word frequencies\")\n",
    "    if not cmudict_pronunciations[word]:\n",
    "        print(f\"{word} not in cmudict\")\n",
    "why_is_this_word_absent('poo')\n",
    "why_is_this_word_absent('shamrocks')\n",
    "why_is_this_word_absent('midrash')\n",
    "why_is_this_word_absent('badges')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9918b66f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rash\n",
      "rash\n",
      "rash\n",
      "rash\n"
     ]
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| code-fold: true\n",
    "#| code-summary: debugging the candidate pain words for a given champagne word\n",
    "\n",
    "# debugging\n",
    "candidate_champagne_word = \"midrash\"\n",
    "sham_syllable = word_pronunciations[\"mid\"][0]\n",
    "for champagne_prons in zip(strict_common_noun_pronunciations.get(candidate_champagne_word, []), \n",
    "                reduced_common_noun_pronunciations.get(candidate_champagne_word, [])):\n",
    "    for champagne_pron in champagne_prons:\n",
    "        if sham_syllable != champagne_pron[:len(sham_syllable)] and \\\n",
    "           reduce_phonemes(sham_syllable, vowel_strictness=2) != champagne_pron[:len(sham_syllable)]: \n",
    "            print(\"{} doesn't match {}, skipping\".format(sham_syllable, champagne_pron))\n",
    "            continue\n",
    "        for pronunciations, syllable_offset in list(itertools.product(\n",
    "            [strict_common_noun_pronunciations, reduced_common_noun_pronunciations], \n",
    "            [0, 1])\n",
    "                                                   ):\n",
    "            for pain_word, pain_prons in sorted(pronunciations.items(), key=lambda word_prons: -word_frequencies.get(word[0], 0)):\n",
    "                if (champagne_pron[len(sham_syllable)-syllable_offset:] in pain_prons):\n",
    "                    print(pain_word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c0d5ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78479909",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
