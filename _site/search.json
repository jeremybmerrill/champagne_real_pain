[
  {
    "objectID": "champagnerealpain.html",
    "href": "champagnerealpain.html",
    "title": "Champagne for my real friends",
    "section": "",
    "text": "What a catchy phrase. Someone nerd-sniped me in July, essentially daring me to find some more. Here’s how I tricked the computer into coming up with more champagne phrases like this, using natural language processing tools like"
  },
  {
    "objectID": "champagnerealpain.html#but-how-do-computers-know-how-words-sound",
    "href": "champagnerealpain.html#but-how-do-computers-know-how-words-sound",
    "title": "Champagne for my real friends",
    "section": "But how do computers know how words sound?",
    "text": "But how do computers know how words sound?\nThe CMU Pronouncing Dictionary is a classical natural language processing resource that lists words and their pronunciations. It’s thirty years old! It was compiled by humans who painstakingly listed each word’s pronunciations – no neural nets or artificial intelligence here.\n\n\n\n\n\n\nWhat is classical NLP? Why not use ChatGPT?\n\n\n\n\n\nSo-called classical natural language processing relies on computational representations of the kinds of grammar concepts used by linguists. Think back to middle-school English class. You learned about nouns and verbs and how to diagram a sentence. Natural language processing analyzes language with those kinds of representations.\nThis differs from AI-based NLP, whose representation of language tends to be more of black box. That black box representation is good for a lot of things, but it’s famously terrible at computational humor.\nHere’s what ChatGPT gave me when I asked it for can you come up with some variants on the “champagne for my real friends, real pain for my sham friends?” template, but using different words than champagne, sham and pain?.\n\n“Laughter for my true friends, heartfelt tears for my false friends.”\n“Confetti for my loyal friends, bitter truth for my deceitful friends.”\n“Hugs for my genuine friends, icy distance for my deceptive friends.”\n“Sunshine for my authentic friends, thunderstorms for my treacherous friends.”\n\nThose are terrible! They don’t follow the template at all! We can do better with classical NLP.\n(But if you can coax better examples out of ChatGPT, let me know!)\n\n\n\nIf we’re gonna find more slogans like champagne for my real friends, real pain for my sham friends, we’ll have to find words like champagne that sound like compounds of a word like sham and a word like pain – regardless of how they’re spelled.\nAnother example of what we’re looking for is focus for my real friends, real cuss for my faux friends. In this example, focus is our champagne compound word, and it’s composed of faux (a sham word) and cuss (a pain word).\nLook below to see what the pronunciation of champagne looks like, and how it’s made up of the pronunciations of sham and pain.\n(Throughout this post, sections of computer code are collapsed. If you want to see the Python code that makes this project work, click the little gray arrow on the left to expand the code.)\n\n\nprint a few pronunciations\nimport cmudict\ncmudict_dict = cmudict.dict()\n\nfor word in [\"champagne\", \"sham\", \"pain\"]:\n    print(\"pronunciation of {} is {}\".format(word, cmudict_dict[word]))\n\n\npronunciation of champagne is [['SH', 'AE0', 'M', 'P', 'EY1', 'N']]\npronunciation of sham is [['SH', 'AE1', 'M']]\npronunciation of pain is [['P', 'EY1', 'N']]"
  },
  {
    "objectID": "champagnerealpain.html#an-initial-rubric-for-a-champagne-phrase",
    "href": "champagnerealpain.html#an-initial-rubric-for-a-champagne-phrase",
    "title": "Champagne for my real friends",
    "section": "An initial rubric for a champagne phrase",
    "text": "An initial rubric for a champagne phrase\nA champagne phrase: sham word is an adjective and a pain word is a word that, when their pronunciations are combined, make a champagne compound word.\nWe’ll revise this later, but this is enough to try to get started with generating champagne phrases."
  },
  {
    "objectID": "champagnerealpain.html#implementing-our-initial-rubric",
    "href": "champagnerealpain.html#implementing-our-initial-rubric",
    "title": "Champagne for my real friends",
    "section": "Implementing our initial rubric",
    "text": "Implementing our initial rubric\nLet’s use “faux” as our sham word. So we’re looking for phrases like faux pain for my real friends, real pain for my faux friends… except where faux pain is a real word.\nSo, now, let’s find our champagne compound words, but starting with the sound “faux”.\n\nCleaning up the pronunciations\nThe pronunciations in our example above almost match, but not quite.\nchampagne: [['SH', 'AE0', 'M', 'P', 'EY1', 'N']]\nsham:      [['SH', 'AE1', 'M']]\npain:                        [['P', 'EY1', 'N']]\nThe problem is that the vowel in sham (AE1) isn’t quite the same as the first vowel in champagne (AE0). The numbers represent stress. 1 is primary stress; 2 is secondary, and 0 is no stress. We don’t really care about stress for our joke format, so we will “clean” the data to ignore stress.\n\n\ndef remove_stress(phon):\ndef remove_stress(phon):\n    return ''.join(i for i in phon if not i.isdigit())\n\ndef clean_phonemes(pron):\n    pron = tuple(remove_stress(phon) for phon in pron) # remove stress        \n    return pron\n\n# map nouns to their \"cleaned\" pronunciations\nword_pronunciations = {}\nfor word, prons in cmudict_dict.items():\n    word_pronunciations[word] = [clean_phonemes(pron) for pron in prons]\n\n\n\n\ndef find_candidate_champagne_compound_words(word_prons):\n# Due to an error in the CMU pronouncing dictionary, we have to specify that _faux_ \n# is actually pronounced like _foe_. (Not like _fox_.)\nSHAM_WORD_OVERRIDE = \"foe\" # None or \"foe\" # in case the pronunciation of the TARGET_WORD is wrong, as it oddly is for \"faux\"\nSHAM_SYLLABLE = word_pronunciations[SHAM_WORD_OVERRIDE or SHAM_WORD][0]\n\nHOW_MANY_TO_SHOW = 15\n\ndef find_candidate_champagne_compound_words(word_prons, sham_syllable=SHAM_SYLLABLE):\n    \"\"\"\n    champagne compound words have to start with the same sounds as the cham word (but can't be identical, it has to be longer!)\n    \"\"\"\n    word, prons = word_prons # destructuring\n    return any([                                              # candidate words must:\n               pron[:len(sham_syllable)] == sham_syllable and # start with same sounds\n               pron != sham_syllable                          # but be different\n            for pron in prons])\n\nnouns_starting_with_sham_word = list(filter(find_candidate_champagne_compound_words, word_pronunciations.items()))\nprint(\"Here are words (our candidate champagne compound words) that start with {}\".format(SHAM_SYLLABLE))\nfor noun, prons in nouns_starting_with_sham_word[:HOW_MANY_TO_SHOW]:\n    print(f\" - {noun}: {prons}\")\nif len(nouns_starting_with_sham_word) &gt; HOW_MANY_TO_SHOW:\n    print(\"and {} additional words hidden\".format(len(nouns_starting_with_sham_word) - HOW_MANY_TO_SHOW))\n\n\nHere are words (our candidate champagne compound words) that start with ('F', 'OW')\n - faucette: [('F', 'OW', 'S', 'EH', 'T')]\n - faucheux: [('F', 'OW', 'SH', 'OW')]\n - faupel: [('F', 'OW', 'P', 'EH', 'L')]\n - fauteux: [('F', 'OW', 'T', 'OW')]\n - foal: [('F', 'OW', 'L')]\n - foale: [('F', 'OW', 'L')]\n - foale's: [('F', 'OW', 'L', 'Z')]\n - foaling: [('F', 'OW', 'L', 'IH', 'NG')]\n - foam: [('F', 'OW', 'M')]\n - foaming: [('F', 'OW', 'M', 'IH', 'NG')]\n - foams: [('F', 'OW', 'M', 'Z')]\n - foamy: [('F', 'OW', 'M', 'IY')]\n - fobel: [('F', 'OW', 'B', 'AH', 'L')]\n - fobel's: [('F', 'OW', 'B', 'AH', 'L', 'Z')]\n - fobes: [('F', 'OW', 'B', 'Z')]\nand 154 additional words hidden\n\n\n\n\nFinding pain words\nFor each of our candidate champagne compound words (folklore, folder, etc.), we’re going to check and see if it contains a pain word. That is, we’re asking if klore or lder are words – even if they’re spelled differently.\nWe do this really naively, by looping through every pronunciation of every single word in the dictionary, to see if matches the second half of the pronunciation of our candidate champagne compound word.\n\n\n{} for my real friends, real {} for my {} friends\ncount_so_far = 0\nHOW_MANY_TO_SHOW = 15\ntotal = 0\n\nfor candidate_word, candidate_prons in nouns_starting_with_sham_word:\n    for pron in candidate_prons:\n        for word, prons in word_pronunciations.items():\n            if (pron[len(SHAM_SYLLABLE):] in prons) or (pron[len(SHAM_SYLLABLE)-1:] in prons):\n                count_so_far += 1\n                if count_so_far &lt;= HOW_MANY_TO_SHOW: \n                    print(\"{} for my real friends, real {} for my {} friends\".format(candidate_word, word, SHAM_WORD))\nif count_so_far &gt; HOW_MANY_TO_SHOW:\n    print(f\"... ({count_so_far - HOW_MANY_TO_SHOW} additional examples hidden)\")\n\n\nfaucette for my real friends, real set for my faux friends\nfaucette for my real friends, real sette for my faux friends\nfaucheux for my real friends, real chau for my faux friends\nfaucheux for my real friends, real schau for my faux friends\nfaucheux for my real friends, real show for my faux friends\nfaupel for my real friends, real pehl for my faux friends\nfaupel for my real friends, real pell for my faux friends\nfaupel for my real friends, real pelle for my faux friends\nfauteux for my real friends, real toe for my faux friends\nfauteux for my real friends, real tow for my faux friends\nfauteux for my real friends, real towe for my faux friends\nfoal for my real friends, real ohl for my faux friends\nfoal for my real friends, real ol' for my faux friends\nfoal for my real friends, real ole for my faux friends\nfoale for my real friends, real ohl for my faux friends\n... (224 additional examples hidden)\n\n\nVery cool! Those are kind of right.\nfocusing for my real friends, real kissing for my faux friends has got a ring to it, but kind of has the wrong valence. Who wishes kisses on their faux friends? Our pain word should be negative; and the champagne compound word should be positive, or at least neutral.\nBut let’s look closer.\n\nfoamy for my real friends, real me for my faux friends\n\nThis is kind of funny, but foamy is an adjective. That means that the phrase doesn’t make a lot of sense. Let’s try to skip those.\n\nfocus for my real friends, real cos for my faux friends\nfocus for my real friends, real kiss for my faux friends\nfocus for my real friends, real kos for my faux friends\n\nSome of the proposals are doubled. And, cos and kos aren’t words I’ve heard of, we should try to eliminate those."
  },
  {
    "objectID": "champagnerealpain.html#a-more-robust-rubric-for-champagne-phrases",
    "href": "champagnerealpain.html#a-more-robust-rubric-for-champagne-phrases",
    "title": "Champagne for my real friends",
    "section": "A more robust rubric for champagne phrases",
    "text": "A more robust rubric for champagne phrases\nIn our first attempt at generating these phrases, we noticed a few problems that add up to too many proposed champagne phrases that are too often crappy.\n\nnon-nouns\nweird, very rare words\nmultiple pronunciations of the same sounds\noverprecise vowel matches mean we miss some slant rhymes that should be ok.\nsome of the pain words are actually positive; it doesn’t make sense to wish a real kiss for your faux friends.\n\nOur initial rubric was that a champagne phrase is sham word and a pain word that, when combined, make a champagne compound word.\nWe can revise that to:\nA champagne phrase: a sham word is an adjective and a pain word is a frequent, common noun with a negative meaning that, when their pronunciations are combined (with perhaps a bit of phonological fudging), make a champagne compound word with positive or neutral meaning.\nHere’s our implementation.\n\nPain words and champagne compound words have to be nouns\nLet’s use Wordnet to filter just to words that are common nouns – excluding adjectives and proper nouns. More specifically, for our purposes, a common noun is a word that has a lemma in WordNet that’s classified as a noun and is lower-cased.\nWordnet doesn’t include every word, which means we would inadvertantly exclude gems like these,\n\nfolkrock for my real friends, real croc for my faux friends\nchamonix for real friends, real money for my sham friends\nmidrash for my real friends, real rash for my mid friends\nshampoo for my real friends, real poo for my sham friends\n\nbecause folkrock, chamonix, poo, and midrash aren’t in Wordnet. (The first three are in the CMU Pronouncing Dictionary.) So we add them back here as special extra nouns.\n(And we definitely do want folkrock for my real friends, real croc for my faux friends, because it lets us show this wonderful, low-effort piece of AI-art of a vengeful Americana banjo player.) \n\n\ndef is_noun(word):\nfrom nltk.stem import WordNetLemmatizer\nwnl = WordNetLemmatizer()\n\n\ndef is_common_noun(word):\n    \"\"\"\n    A word is a common noun (versus a proper noun) if its lemma is lowercase\n    or the word itself is present as a lemma in wordnet.\n\n    A lemma is a root word with any morphology removed, like `squirrel` is the lemma for \"squirrels\".\n    \n    For unknown reasons (perhaps a bug), the NLTK implementation of Wordnet's tokenizer returns a lemma\n    of \"Te\" for \"tess\" (referring to the element Tellurium), or \"Ca\" (an abbreviation for California).\n\n    Another noun's lemma (as generated by NLTK's WordNetLemmatizer) isn't contained in Wordnet, but the\n    raw form of the word itself is. (I don't remember which word). That's why we include `word in wordnet_lemmas`.\n    \"\"\"\n    input_lemma = wnl.lemmatize(word, pos='n')\n    wordnet_lemmas = [lemma.name() for lemma in wordnet.synsets(word, pos=wordnet.NOUN)[0].lemmas()]\n\n    return input_lemma in wordnet_lemmas or word in wordnet_lemmas\n    \nassert not is_common_noun(\"mecca\")\nassert not is_common_noun(\"dawson\")\nassert not is_common_noun(\"ca\")\nassert not is_common_noun(\"dc\")\nassert not is_common_noun(\"tess\")\nassert is_common_noun(\"toes\")\nassert is_common_noun(\"champagne\")\nassert is_common_noun(\"medics\")\n\ndef is_noun(word):\n    \"\"\"\n    A word is a noun if it is present in wordnet as a noun AND it is a common noun.\n    \"\"\"\n    return any(synset for synset in wordnet.synsets(word, pos=wordnet.NOUN) if is_common_noun(word)) or word in EXTRA_NOUNS\n\nassert is_noun('mite')      # testing basic case\nassert is_noun('might')     # testing words that can be multiple PoS\nassert is_noun('shamrocks') # testing plurals\nassert is_noun('mites')     # testing plurals\nassert is_noun('poo')       # testing manual additions\nassert not is_noun('photographed')     # testing handling of inflected verbs\nassert not is_noun('focused')          # testing handling of inflected verbs\n\n\n\n\nIgnore very rare words\nFirst, we download a list of word frequencies; we’ll ignore anything that occurs less than 500,000 times in the corpus. Then, we download a list of nouns; we’ll ignore anything that isn’t a noun. (We also add back a few nouns I like.)\n\n\ndownload file of the 1/3 million most frequent words, with counts\n# ignore words that occur less than this many times in the Google Web Trillion Word Corpus \n# many of these less-frequent words are very bizarre, but appear in the CMU Pronouncing Dictionary nevertheless.\n# the champagne and sham words can be rare, but they must be nouns.\n# the pain word must be a more common noun.\n\n# download file of \"The 1/3 million most frequent words, all lowercase, with counts\"\n!wget -nc --quiet https://norvig.com/ngrams/count_1w.txt\nimport csv\nwith open(\"count_1w.txt\") as f:\n    word_frequencies = dict([(row[0], int(row[1])) for row in csv.reader(f, delimiter=\"\\t\")])\n\nMIN_FREQUENCY = 100_000\n\n\n\n\nMore permissive vowel matching\nWe also don’t care about all the vowel distinctions that the dictionary uses. We’ll implement “vowel reductions” that mirror some of the ways American English speakers can change vowels in fast or casual speech, so that near-identical words are okay.\nAlso we ignore very uncommon words and non-nouns, which don’t fit in the joke format.\n\n\n\n\n\n\nWhat are these vowels?\n\n\n\n\n\n\n\nfinding examples of each vowel, so we can find which vowels to combine\ntry:\n    import pandas as pd\n    has_pandas = True\nexcept:\n    has_pandas = False\n    \nvowels = [ph for ph, types in cmudict.phones() if types[0] == 'vowel']\nvowel_examples = []\nfor vowel in vowels:\n    for word, prons in sorted(cmudict_dict.items(), key=lambda word_prons: -word_frequencies.get(word_prons[0], 0)):\n        if \"'\" in word or '.' in word: continue\n        if not is_noun(word): continue\n        if 'R' in prons[0]: continue\n        if len(word) &lt; 3 or len(word) &gt;= 6: continue\n\n        if vowel in clean_phonemes(prons[0]):\n            vowel_examples.append((vowel, word, prons[0]))\n            break\nif has_pandas:\n    display(pd.DataFrame(vowel_examples, columns=[\"vowel\", \"example\", \"pronunciation\"]).set_index('vowel'))\nelse:\n    for vowel, example, pron in vowel_examples:\n        print(vowel, example, pronunciation)\n    \n\n\n\n\n\n\n\n\n\nexample\npronunciation\n\n\nvowel\n\n\n\n\n\n\nAA\ntop\n[T, AA1, P]\n\n\nAE\nhave\n[HH, AE1, V]\n\n\nAH\none\n[W, AH1, N]\n\n\nAO\nlaw\n[L, AO1]\n\n\nAW\nout\n[AW1, T]\n\n\nAY\ntime\n[T, AY1, M]\n\n\nEH\nweb\n[W, EH1, B]\n\n\nER\nfirst\n[F, ER1, S, T]\n\n\nEY\npage\n[P, EY1, JH]\n\n\nIH\nwill\n[W, IH1, L]\n\n\nIY\nsee\n[S, IY1]\n\n\nOW\nhome\n[HH, OW1, M]\n\n\nOY\npoint\n[P, OY1, N, T]\n\n\nUH\ngood\n[G, UH1, D]\n\n\nUW\nnews\n[N, UW1, Z]\n\n\n\n\n\n\n\n\n\n\n\n\ndef reduce_phonemes(pron):\nVOWEL_REDUCTIONS = {\n    \"AH\": \"AH\", \"AA\": \"AH\", \"AO\": \"AH\", \"UH\": \"AH\", \"IH\": \"AH\", \"EH\": \"AH\", \n    \"OW\": \"AH\" # special for chamonix / money\n}\n\nVOWEL_STRICTNESS = 2\n# 1 = least; compare only first char of vowel symbol \n# 2 = medium; perform some vowel reductions\n# 3 = most; compare vowels as is (with stress removed)\n\ndef is_vowel(phon):\n    return phones_dict[remove_stress(phon)][0] == 'vowel'\n\nphones_dict = dict(cmudict.phones())\ndef reduce_phonemes(pron, vowel_strictness=VOWEL_STRICTNESS):\n    if vowel_strictness &lt; 3:\n        pron = [(phon[0] if (vowel_strictness == 1) else VOWEL_REDUCTIONS.get(remove_stress(phon), phon)) if is_vowel(phon) else phon for phon in pron]\n    pron = clean_phonemes(pron) # remove stress        \n    return pron\n    \n# `assert` lines are tests to make sure I didn't F it up.\nprint(\"pronunciation of 'ruck', as is    {}\"  .format(          tuple(cmudict_dict[\"ruck\"][0])))\nprint(\"pronunciation of 'ruck', cleaned  {}\".format( reduce_phonemes(cmudict_dict[\"ruck\"][0], vowel_strictness=2)))\nassert reduce_phonemes(cmudict.dict()[\"ruck\"][0], vowel_strictness=2)[1] == \"AH\"\n\nprint(\"pronunciation of 'wreck', as is   {}\"  .format(          tuple(cmudict_dict[\"wreck\"][0])))\nprint(\"pronunciation of 'wreck', cleaned {}\".format( reduce_phonemes(cmudict_dict[\"wreck\"][0], vowel_strictness=2)))\nassert reduce_phonemes(cmudict.dict()[\"wreck\"][0], vowel_strictness=2)[1] == \"AH\"\n\nassert reduce_phonemes(cmudict.dict()[\"ruck\"][0], vowel_strictness=1)[1] == \"A\"\nassert reduce_phonemes(cmudict.dict()[\"wreck\"][0], vowel_strictness=1)[1] == \"E\"\n\nassert reduce_phonemes(cmudict.dict()[\"ruck\"][0], vowel_strictness=3)[1] == \"AH\"\nassert reduce_phonemes(cmudict.dict()[\"wreck\"][0], vowel_strictness=3)[1] == \"EH\"\n\n\npronunciation of 'ruck', as is    ('R', 'AH1', 'K')\npronunciation of 'ruck', cleaned  ('R', 'AH', 'K')\npronunciation of 'wreck', as is   ('R', 'EH1', 'K')\npronunciation of 'wreck', cleaned ('R', 'AH', 'K')\n\n\n\n\nChampagne compound words are positive, pain words are negative\nfomite for my real friends, real might for my faux friends doesn’t really make sense. You want to wish something bad on your faux friends, not something good, like might! And fomites are infection-carrying particles – which we don’t really want to wish on our real friends! So we want to filter our candidate words to ensure that the champagne compound words are positive and pain words are negative.\nBut the concept of negativity that we’re trying to capture here is really complex.\nThis attempt uses GLoVe embeddings. For pain words, it accepts only words that are closer to the average embedding of some negative words (like bad, painful) and some handpicked pain words I particularly like (like tricks and cuss) than to the average embedding of some positive words and some handpicked champagne compound words. (Champagne compound words are filtered to be the opposite.)\nIt also doesn’t work perfectly.\n\n\nclassifying with handpicked positive and negative words\nimport gensim.downloader as gensim_downloader\nif 'glove_model' not in locals():\n    glove_model = gensim_downloader.load(\"glove-wiki-gigaword-200\")\n\n# handpicked positive words and champagne compound words that I like, plus some attempted corrections\nHANDPICKED_POSITIVE_WORDS = [\"positive\", \"positivity\", \"good\", \"healthy\", \"safe\", \"normal\", \"beautiful\", \"pea\", \"tagine\", \"fondue\"]\nHANDPICKED_CHAMPAGNE_COMPOUND_WORDS = [\"champagne\", \"metrics\", \"focus\", \"shamrocks\", \"photos\", \"medics\"]\nPOSITIVE_WORDS = HANDPICKED_POSITIVE_WORDS + HANDPICKED_CHAMPAGNE_COMPOUND_WORDS + [\"kisses\", \"jewish\", \"midrash\"]\n\n# handpicked negative words and pain words that I like\nHANDPICKED_NEGATIVE_WORDS = [\"bad\", \"badness\", \"evil\", \"painful\", \"dangerous\", \"negative\", \"weird\", \"ugly\"]\nHANDPICKED_PAIN_WORDS = [\"pain\", \"tricks\", \"cuss\", \"rocks\", \"feet\", \"rash\", \"dicks\", \"crocodile\", \"lenin\", \"money\"]\nNEGATIVE_WORDS = HANDPICKED_NEGATIVE_WORDS + HANDPICKED_PAIN_WORDS\n\n\n\n\ndef is_negative(word)\n# handpicked\nPOSITIVE_SENTIMENT_CUTOFF = 0.25\nNEGATIVE_SENTIMENT_CUTOFF = 0.045\n\ndef pos_neg_similarities(word):\n    \"\"\"\n    return `word`'s cosine-similarity to the average of POSITIVE_WORDS and of NEGATIVE_WORDS\n    \"\"\"\n    try:\n        pos_similarity = glove_model.n_similarity([word], POSITIVE_WORDS)\n        neg_similarity = glove_model.n_similarity([word], NEGATIVE_WORDS)\n    except KeyError:\n        return 0.0, 0.0\n    return pos_similarity, neg_similarity\n    \ndef is_negative(pain_word, default=False):\n    \"\"\"\n    True if `pain_word`'s cosine-similarity is closer to NEGATIVE_WORDS than to POSITIVE_WORDS, \n    or is close enough (with the ratio less than NEGATIVE_SENTIMENT_CUTOFF)\n    \"\"\"\n    pos_similarity, neg_similarity = pos_neg_similarities(pain_word)\n    if pos_similarity == 0.0 or neg_similarity == 0.0:\n        return default\n    return (neg_similarity &gt; pos_similarity) or \\\n           ((pos_similarity - neg_similarity) / pos_similarity) &lt; NEGATIVE_SENTIMENT_CUTOFF\n\ndef is_positive(champagne_compound_word, default=True):\n    \"\"\"\n    True if `champagne_compound_word`'s cosine-similarity is closer to POSITIVE_WORDS than to NEGATIVE_WORDS, \n    or is close enough (with the ratio less than POSITIVE_SENTIMENT_CUTOFF)\n    \"\"\"\n    pos_similarity, neg_similarity = pos_neg_similarities(champagne_compound_word)\n    if pos_similarity == 0.0 or neg_similarity == 0.0:\n        return default        \n    return (pos_similarity &gt; neg_similarity) or \\\n           ((neg_similarity - pos_similarity) / neg_similarity) &lt; POSITIVE_SENTIMENT_CUTOFF\n\nassert not is_negative(\"kissing\")\nassert not is_positive(\"badness\")\nassert not is_negative(\"midrash\")\nassert not is_positive(\"rash\")\n\n\nGLoVe works by translating each word to a series of coordinates, across 200 dimensions. (GLoVe gets those coordinates with machine-learning, deducing that words that occur in similar sentences probably mean similar things.) You can see in this chart that the words we consider positive cluster on the bottom left of the chart, and the ones we consider negative are more towards the top and right.\n\n\nplotting positive and negative words on a t-SNE chart\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\n \nfrom sklearn.decomposition import PCA\nfrom sklearn.manifold import TSNE\n\n# tsne plot of my handpicked words and a bunch of champagne-words and pain words\n\nsham_words = [\"meh\", \"sham\", \"faux\", \"bad\", \"mid\"]\noverrides = {\"faux\": \"foe\"}\n\n# make a list of relevant candidate pain words and champagne compound words to be plotted in the t-SNE chart\ncandidate_champagne_compound_words = []\ncandidate_pain_words = []\nfor sham_word in [\"meh\", \"sham\", \"faux\", \"bad\", \"mid\"]:\n    sham_syllable = strict_word_pronunciations[overrides.get(sham_word, sham_word)][0]\n    nouns_starting_with_sham_word = list(filter(\n        lambda candidate_word: find_candidate_champagne_compound_words(candidate_word, sham_syllable=sham_syllable), \n        strict_noun_pronunciations.items()))\n    candidate_champagne_compound_words += [n for n, pron in nouns_starting_with_sham_word]\n\n    for candidate_champagne_compound_word, _ in nouns_starting_with_sham_word:\n        for candidate_champagne_prons in zip(strict_frequent_noun_pronunciations.get(candidate_champagne_compound_word, []), \n                reduced_frequent_noun_pronunciations.get(candidate_champagne_compound_word, [])):\n            for champagne_pron in candidate_champagne_prons:\n    \n                if sham_syllable != champagne_pron[:len(sham_syllable)] and \\\n                   reduce_phonemes(sham_syllable, vowel_strictness=2) != champagne_pron[:len(sham_syllable)]: \n                    # print(\"{} doesn't match {}, skipping\".format(sham_syllable, champagne_pron)) # just for debug.\n                    continue\n                for (pronunciations, syllable_offset), score in zip(list(itertools.product(\n                    [strict_frequent_noun_pronunciations, reduced_frequent_noun_pronunciations], \n                    [0, 1])\n                                                           ), range(4, 0, -1)):\n                    # gemination is only allowed for consonant-final sham words.\n                    # \"photograph for my real friends, real autograph for my faux friends\" should be invalid\n                    if syllable_offset == 1 and is_vowel(sham_syllable[-1]): continue\n                    for pain_word, pain_prons in sorted(pronunciations.items(), key=lambda word_prons: -word_frequencies.get(word[0], 0)):\n                        if (champagne_pron[len(sham_syllable)-syllable_offset:] in pain_prons):\n                            candidate_pain_words.append(pain_word)\ncandidate_pain_words = list(set(candidate_pain_words))\n\n# translating the list of words to a Numpy array of the GLoVe vectors for the words\nPCA_N_COMPONENTS = 21\nwords = POSITIVE_WORDS + NEGATIVE_WORDS + candidate_champagne_compound_words + candidate_pain_words\nwords = [word for word in words if word in glove_model]\nwords = list(set(words)) # remove duplicates\nvectors = np.array([glove_model[word] for word in words] + \n                   [np.mean([glove_model[word] for word in POSITIVE_WORDS], axis=0)] + \n                   [np.mean([glove_model[word] for word in NEGATIVE_WORDS], axis=0)])\nwords += [\"mean(POSITIVE_WORDS)\", \"mean(NEGATIVE_WORDS)\"]\n\n# reducing the dimensionality of those vectors from 200 dimension to 2 with PCA and then t-SNE \npca_reduced_vectors = PCA(n_components=PCA_N_COMPONENTS).fit_transform(vectors)\nnp.set_printoptions(suppress=True)\nY = TSNE(n_components=2, random_state=0).fit_transform(pca_reduced_vectors)\n    \n# plotting it\ndf = pd.DataFrame({'x': [x for x in Y[:, 0]],\n                   'y': [y for y in Y[:, 1]],\n                   'words': words})\ndf[\"is_positive\"] = df.words.apply(is_positive)\ndf[\"is_negative\"] = df.words.apply(is_negative)\n\ndf[\"color\"] = None\ndf[\"handpicked\"] = df.words.apply(lambda x: x in HANDPICKED_POSITIVE_WORDS + HANDPICKED_NEGATIVE_WORDS)\ndf[\"marker\"] = df.handpicked.apply(lambda x: \"o\" if x else \".\")\ndf.loc[df.is_positive, 'color'] = \"red\"\ndf.loc[df.is_negative, 'color'] = \"blue\"\ndf.loc[df.words == \"mean(POSITIVE_WORDS)\", 'color'] = 'red'\ndf.loc[df.words == \"mean(NEGATIVE_WORDS)\", 'color'] = 'blue'\n#df.loc[df.is_positive & df.is_negative, 'color'] = \"yellow\"\ndf.set_index('words', inplace=True)\n\nword_df = df[~df.index.str.contains(\"mean(\", regex=False)]\navg_df = df[df.index.str.contains(\"mean(\", regex=False)]\nfor polarity in [True, False]:\n    subdf = word_df[word_df.is_positive == polarity]\n    plt.scatter(subdf.x, subdf.y, c=subdf.color.tolist(), marker='.', label=\"positive\" if polarity else \"negative\")\nplt.scatter(avg_df.x, avg_df.y, c=avg_df.color.tolist(), marker='o')\nplt.gca().legend()\n\nfor word in [\"mean(POSITIVE_WORDS)\", \"mean(NEGATIVE_WORDS)\"]:    \n    plt.gca().annotate(word, (df.loc[word].x, df.loc[word].y))"
  },
  {
    "objectID": "champagnerealpain.html#implementing-our-final-rubric-for-champagne-phrases",
    "href": "champagnerealpain.html#implementing-our-final-rubric-for-champagne-phrases",
    "title": "Champagne for my real friends",
    "section": "Implementing our final rubric for champagne phrases",
    "text": "Implementing our final rubric for champagne phrases\n\n\ndef get_best_pain_word(champagne_prons, sham_syllable):\ndef get_best_pain_word(champagne_prons, sham_syllable, quiet=True, filter_by_sentiment=True):\n    \"\"\"\n    find the most common word that matches the back half of the champagne compound word\n    if we can't find one, find one that matches the back half of the champagne compound word, \n        but repeating the last phoneme of the sham word \n        (e.g. chamonix for my real friends, real money for my sham friends)\n        this is \"gemination\" -- we double up the \n    if we still can't find one, try with reduced pronunciations\n    \"\"\"\n\n    # this lets us prefer better vowel matches to worse ones, i.e.\n    # ok: folkrock for my real friends, real crook for my faux friends\n    # better: folkrock for my real friends, real croc for my faux friends\n    # previously it prefers \"crook\" because crook is more frequent than croc\n\n    # this also lets us prefer ungeminated matches over geminated ones\n    \n    for champagne_pron in champagne_prons:\n        if sham_syllable != champagne_pron[:len(sham_syllable)] and \\\n           reduce_phonemes(sham_syllable, vowel_strictness=2) != champagne_pron[:len(sham_syllable)]: \n            # print(\"{} doesn't match {}, skipping\".format(sham_syllable, champagne_pron)) # just for debug.\n            continue\n        for (pronunciations, syllable_offset), score in zip(list(itertools.product(\n            [strict_frequent_noun_pronunciations, reduced_frequent_noun_pronunciations], \n            [0, 1])\n                                                   ), range(4, 0, -1)):\n            # gemination is only allowed for consonant-final sham words.\n            # \"photograph for my real friends, real autograph for my faux friends\" should be invalid\n            if syllable_offset == 1 and is_vowel(sham_syllable[-1]): continue\n            for pain_word, pain_prons in sorted(pronunciations.items(), key=lambda word_prons: -word_frequencies.get(word[0], 0)):\n                if (champagne_pron[len(sham_syllable)-syllable_offset:] in pain_prons) and (is_negative(pain_word) or not filter_by_sentiment):\n                    return pain_word, score\n    return None, None\n\n\n\n\ndef find_champagne_real_pain_phrases(‘faux’):\nfrom collections import defaultdict\n\ndef find_champagne_real_pain_phrases(sham_word, sham_word_override=None, real_word=\"real\", quiet=True, filter_by_sentiment=True):\n    # sham syllables can be any PoS and need to have the extras added.\n    # e.g. \"mid\" and \"faux\" are adjectives; \"meh\" isn't in the CMU pron dictionary.\n    sham_syllable = strict_word_pronunciations[sham_word_override or sham_word][0]\n    \n    nouns_starting_with_sham_word = list(filter(\n        lambda candidate_word: find_candidate_champagne_compound_words(candidate_word, sham_syllable=sham_syllable), \n        strict_noun_pronunciations.items()\n    ))\n    if not quiet:\n        print(\"Here are words (our candidate champagne compound words) that start with {}\".format(sham_syllable))\n        for noun, prons in nouns_starting_with_sham_word:\n            print(f\" - {noun}: {prons}\")\n    champagne_pain_pairs = set()\n    for candidate_champagne_compound_word, _ in nouns_starting_with_sham_word:\n        if filter_by_sentiment and not is_positive(candidate_champagne_compound_word): continue\n        for candidate_champagne_prons in zip(strict_frequent_noun_pronunciations.get(candidate_champagne_compound_word, []), \n                reduced_frequent_noun_pronunciations.get(candidate_champagne_compound_word, [])):\n            best_pain_word, score = get_best_pain_word(candidate_champagne_prons, sham_syllable, filter_by_sentiment=filter_by_sentiment)\n            if best_pain_word:\n                champagne_pain_pairs.add((candidate_champagne_compound_word, best_pain_word, score))    \n        \n    return [((f\"{candidate_champagne_compound_word} for my {real_word} friends, {real_word} {pain_word} for my {sham_word} friends\"),\n            {\"candidate_champagne_compound_word\": candidate_champagne_compound_word, \"real_word\": real_word, \"pain_word\": pain_word, \"sham_word\": sham_word, \"score\": score})\n            for candidate_champagne_compound_word, pain_word, score in sorted(champagne_pain_pairs, key=lambda x: -x[2])]"
  },
  {
    "objectID": "champagnerealpain.html#for-my-faux-sham-mid-meh-and-bad-friends",
    "href": "champagnerealpain.html#for-my-faux-sham-mid-meh-and-bad-friends",
    "title": "Champagne for my real friends",
    "section": "____ for my faux, sham, mid, meh and bad friends",
    "text": "____ for my faux, sham, mid, meh and bad friends\n\n\nFinding champagne phrases if our sham word is … ‘faux’\n# SHAM_WORD and SHAM_WORD_OVERRIDE were defined in the \"A first try\" section\n# SHAM_WORD = faux\nfor champagne_phrase, _ in find_champagne_real_pain_phrases(SHAM_WORD, sham_word_override=SHAM_WORD_OVERRIDE):\n    print(champagne_phrase)\n\n\nfolkrock for my real friends, real croc for my faux friends\nfomite for my real friends, real might for my faux friends\nphoto for my real friends, real toe for my faux friends\nphotons for my real friends, real tons for my faux friends\nfomites for my real friends, real mites for my faux friends\nfocus for my real friends, real cuss for my faux friends\nphotos for my real friends, real toes for my faux friends\nphoton for my real friends, real ton for my faux friends\nfocus for my real friends, real kis for my faux friends\nfolklore for my real friends, real clear for my faux friends\nfoliage for my real friends, real ledge for my faux friends\n\n\n\n\nFinding champagne phrases if our sham word is … ‘sham’\nfor champagne_phrase, _ in find_champagne_real_pain_phrases(\"sham\"):\n    print(champagne_phrase)\n\n\nshamrocks for my real friends, real rocks for my sham friends\nchampagnes for my real friends, real pains for my sham friends\nchampagne for my real friends, real pain for my sham friends\nshamwow for my real friends, real wow for my sham friends\nshamrock for my real friends, real rock for my sham friends\nshampoo for my real friends, real poo for my sham friends\nchamonix for my real friends, real money for my sham friends\nchamois for my real friends, real woe for my sham friends\n\n\n\n\n… if our sham word is ‘mid’\nfor champagne_phrase, _ in find_champagne_real_pain_phrases(\"mid\"):\n    print(champagne_phrase)\n\n\nmidline for my real friends, real line for my mid friends\nmidrash for my real friends, real rash for my mid friends\nmiddling for my real friends, real ling for my mid friends\nmidpoint for my real friends, real point for my mid friends\nmidday for my real friends, real day for my mid friends\nmidnight for my real friends, real knight for my mid friends\nmiddle for my real friends, real ell for my mid friends\nmedulla for my real friends, real ola for my mid friends\n\n\n\n\n… if our sham word is ‘bad’\nfor champagne_phrase, _ in find_champagne_real_pain_phrases(\"bad\"):\n    print(champagne_phrase)\n\n\nbadges for my real friends, real jaws for my bad friends\n\n\n\n\n… if our sham word is ‘meh’\nfor champagne_phrase, _ in find_champagne_real_pain_phrases(\"meh\"):\n    print(champagne_phrase)\n\n\nmarrow for my real friends, real rho for my meh friends\nmerits for my real friends, real ruts for my meh friends\nmedic for my real friends, real dick for my meh friends\nmarried for my real friends, real reed for my meh friends\nmethod for my real friends, real thud for my meh friends\nmeadows for my real friends, real doze for my meh friends\nmerits for my real friends, real writs for my meh friends\nmedics for my real friends, real dicks for my meh friends\nmeadow for my real friends, real doh for my meh friends\nmarriages for my real friends, real ridges for my meh friends\nmarriage for my real friends, real ridge for my meh friends\nmerit for my real friends, real rut for my meh friends\nmetric for my real friends, real trick for my meh friends\nmetrics for my real friends, real tricks for my meh friends\nmetals for my real friends, real tolls for my meh friends\nmedals for my real friends, real dolls for my meh friends\nmedico for my real friends, real deco for my meh friends\nmetal for my real friends, real tall for my meh friends\nmelons for my real friends, real loans for my meh friends\nmedal for my real friends, real dahl for my meh friends\nmeshes for my real friends, real shows for my meh friends\nmessage for my real friends, real sedge for my meh friends\n\n\n\n\n… if our sham word is ‘crap’\nfor champagne_phrase, _ in find_champagne_real_pain_phrases(\"crap\"):\n    print(champagne_phrase)\n\n\ncrappie for my real friends, real pee for my crap friends\n\n\n\n\n… if our sham word is ‘barf’\nfor champagne_phrase, _ in find_champagne_real_pain_phrases(\"barf\"):\n    print(champagne_phrase)\n\n\nbarflies for my real friends, real lies for my barf friends\n\n\n(Crappie is a kind of fish.)\n\n\n… if our sham word is ‘ex’\nfor champagne_phrase, _ in find_champagne_real_pain_phrases(\"ex\"):\n    print(champagne_phrase)\n\n\nexposition for my real friends, real position for my ex friends\nextract for my real friends, real tract for my ex friends\nextraction for my real friends, real traction for my ex friends\nexile for my real friends, real isle for my ex friends\nexpos for my real friends, real pose for my ex friends\nexchequer for my real friends, real checker for my ex friends\nextracts for my real friends, real tracts for my ex friends\nexpert for my real friends, real spurt for my ex friends\nexon for my real friends, real son for my ex friends\nexperts for my real friends, real spurts for my ex friends\nexcess for my real friends, real oss for my ex friends\nexit for my real friends, real aught for my ex friends\nexports for my real friends, real parts for my ex friends\nexpositions for my real friends, real possessions for my ex friends\nexpo for my real friends, real paw for my ex friends\nexport for my real friends, real part for my ex friends\nexponent for my real friends, real pennant for my ex friends\nextras for my real friends, real straws for my ex friends\n\n\n\n\nregression testing\n# regression testing\nassert not any(['photograph' in phrase and 'autograph' in phrase for phrase, _ in find_champagne_real_pain_phrases(\"faux\", sham_word_override=\"foe\")])\nassert any(['shamrocks' in phrase for phrase, _ in find_champagne_real_pain_phrases(\"sham\")])\nassert any(['money' in phrase and 'chamonix' in phrase for phrase, _ in find_champagne_real_pain_phrases(\"sham\")])\nassert any(['midrash' in phrase for phrase, _ in find_champagne_real_pain_phrases(\"mid\")])\nassert any(['folkrock' in phrase for phrase, _ in find_champagne_real_pain_phrases(\"faux\", sham_word_override=\"foe\")])\nassert any([metadata[\"pain_word\"] == \"croc\" for phrase, metadata in find_champagne_real_pain_phrases(\"faux\", sham_word_override=\"foe\")])\nassert any(['fomites' in phrase for phrase, _ in find_champagne_real_pain_phrases(\"faux\", sham_word_override=\"foe\")])\nif NSFW_WORDS_ALLOWED:\n    assert any(['badges' in phrase and unmask_nsfw('aml6eg==') in phrase for phrase, _ in find_champagne_real_pain_phrases(\"bad\")])\nelse:\n    assert not any(['badges' in phrase and unmask_nsfw('aml6eg==') in phrase for phrase, _ in find_champagne_real_pain_phrases(\"bad\")])"
  },
  {
    "objectID": "champagnerealpain.html#a-worked-example",
    "href": "champagnerealpain.html#a-worked-example",
    "title": "Champagne for my real friends",
    "section": "A worked example",
    "text": "A worked example\nLet’s walk through this step by step.\nChamonix is a province in France. It has two very different pronunciations in the CMU Pronouncing Dictionary. One Americanized pronunciation, tcham-onyx and a French one like sham-oh-knee.\n(The Americanized pronunciation – which is incorrect – might be meant for automatic speech recognition systems akin to Siri or Alexa that would have to recognize an incorrect pronunciation, rather than for text-to-speech systems. Or it might be that this particular entry in the CMU Pronouncing Dictionary was generated by an unmotivated undergrad without a background in French.)\n\ncmudict.dict()[\"chamonix\"]\n\n[['CH', 'AE1', 'M', 'AH0', 'N', 'IH0', 'K', 'S'],\n ['SH', 'AE0', 'M', 'OW0', 'N', 'IY0']]\n\n\nHere’s what the pronunciation looks like with the stresses removed.\n\nstrict_word_pronunciations[\"chamonix\"]\n\n[('CH', 'AE', 'M', 'AH', 'N', 'IH', 'K', 'S'),\n ('SH', 'AE', 'M', 'OW', 'N', 'IY')]\n\n\n\nsham_word = \"sham\"\nsham_syllable = strict_word_pronunciations[sham_word][0]\nsham_syllable\n\n('SH', 'AE', 'M')\n\n\nSee how ('SH', 'AE', 'M') is the first half of the second pronunciation, ('SH', 'AE', 'M', 'OW', 'N', 'IY')\nNow, we’re looking to see if there are any pain words that are pronounced like any of these options for the pronunciation of the back half of chamonix.\nFirst, we’re looking for something that matches ('OW', 'N', 'IY') or ('M', 'OW', 'N', 'IY') – the back half without any vowel reductions. ('OW', 'N', 'IY') would be preferable, since it doesn’t require double-up the M in both the sham word (sham) and the pain word (money, in this case).\nHere are those strict pronunciations that we’re looking for.\n\nfor chamonix_pronunciation in strict_word_pronunciations[\"chamonix\"]:\n    print(chamonix_pronunciation[len(sham_syllable):])\n    print(chamonix_pronunciation[len(sham_syllable)-1:])    \n\n('AH', 'N', 'IH', 'K', 'S')\n('M', 'AH', 'N', 'IH', 'K', 'S')\n('OW', 'N', 'IY')\n('M', 'OW', 'N', 'IY')\n\n\nOr, if we can’t find something that matches the strict, we’d look for something that matches the back half of chamonix with reductions.\nHere’s what those reduced pronunciations look like:\n\nfor chamonix_pronunciation in reduced_frequent_noun_pronunciations[\"chamonix\"]:\n    print(chamonix_pronunciation[len(sham_syllable):])\n    print(chamonix_pronunciation[len(sham_syllable)-1:])\n\n('AH', 'N', 'AH', 'K', 'S')\n('M', 'AH', 'N', 'AH', 'K', 'S')\n('AH', 'N', 'IY')\n('M', 'AH', 'N', 'IY')\n\n\nWith those eight acceptable pronunciations in mind, we loop through every noun in the English language, to see if any nouns are pronounced that way. We find three!\n\nstrict_noun_pronunciations[\"money\"]\n\n[('M', 'AH', 'N', 'IY')]\n\n\n\nstrict_noun_pronunciations[\"onyx\"]\n\n[('AA', 'N', 'IH', 'K', 'S')]\n\n\n\nstrict_noun_pronunciations[\"annex\"]\n\n[('AE', 'N', 'EH', 'K', 'S'), ('AH', 'N', 'EH', 'K', 'S')]\n\n\nNone of those three words match either strict pronunciation of chamonix. So we get no result from get_best_pain_word here.\n\nget_best_pain_word(strict_noun_pronunciations[\"chamonix\"], strict_noun_pronunciations[\"sham\"][0])\n\n(None, None)\n\n\nBut they do match the reduced pronunciation of chamonix.\n\nget_best_pain_word(reduced_frequent_noun_pronunciations[\"chamonix\"], strict_noun_pronunciations[\"sham\"][0])\n\n('money', 3)\n\n\nMoney is picked becuase it is the more common than either onyx or annex.\n\nfor word in [\"money\", \"onyx\", \"annex\"]:\n    print(\"frequency of {: &gt;5} is {:,.0f} and it is {}\".format(word, word_frequencies[word], \"negative\" if is_negative(word) else \"positive\"))\n\nfrequency of money is 190,205,072 and it is negative\nfrequency of  onyx is 2,315,135 and it is negative\nfrequency of annex is 8,465,905 and it is positive"
  },
  {
    "objectID": "champagnerealpain.html#future-enhancements",
    "href": "champagnerealpain.html#future-enhancements",
    "title": "Champagne for my real friends",
    "section": "Future enhancements",
    "text": "Future enhancements\n\nUse “a” for pain words that are count nouns\nfor singular, count nouns, we should add “a” (or “an”) before hand, so it makes a bit more sense.\n\na phoney for my real friends, a real knee for my faux friends\n\nthis would be tricky, because we don’t want to do this for mass nouns (like champagne). CUVPlus may be a way to do this, although it regards champagne as a count noun (erroneously, in my view).\nCount nouns are those that you refer to individually. A couch, two laptops, many friends. Mass nouns are referred to regardless of their quantity: coffee, champagne, sand. Some nouns can be both, like squirrel. (I like squirrels means something different from I like squirrel, which implies that you like eating squirrel meat.)\n\n\nMetrics for my real friends\ncompile all the examples here and get some humans to rate them on how funny they are, and see if we can’t figure out some more rules to filter out the crappy ones and generate more funny ones.\n\n\nBetter phonology\nThe vowel reduction logic above is pretty rough. My linguistics education is rusty enough that I can’t write a rule to exclude false-positive matches like medulla for my real friends, real allah for my mid friends.\nAdditionally, diphthongs are often close enough to single vowels to count as a rhyme. You could imagine Champlain for my real friends, real playin’ for my sham friends working, but the code as of now wouldn’t be able to equate plain and playin’.\nThe matching logic could also allow voiced and unvoiced consonants (that share a place of articulation) to match, which would allow sentences like extremes for my real friends, real dreams for my ex friends.\n\n\nImprove positive/negative classification\nIt’d be great to find a better way to classify pain words as negative or not. This is one place where GPT4 might do a good job! A traditional classifier based on the VADER wordlist and GLoVE vectors might also do a good enough job of capturing our very specific sense of positivity/negativity, too.\n\nWhat about VADER (or AFINN)?\nVADER is a time-tested dictionary-based sentiment analysis methodology – that is, it’s a big list of hand-picked words rated by how positive or negative they are. The code below is a first stab at using VADER to filter out pain words that aren’t classified as negative. But the VADER lexicon list is relatively small, and many negative words words – like mites – aren’t on it, so many good phrases get incorrectly excluded. (Another sentiment wordlist, AFINN, only contains pain words already present in VADER.)\nWe’d only get these five results (which are pretty good, but fewer than we’d want) with the VADER methodology.\n\n\nCode\nfrom nltk.sentiment.vader import SentimentIntensityAnalyzer\nnltk_download('vader_lexicon', quiet=True)\ns = SentimentIntensityAnalyzer()\n\noverrides = {\"faux\": \"foe\"}\nfor sham_word in [\"meh\", \"sham\", \"faux\", \"bad\", \"mid\"]:\n    for champagne_phrase, metadata in find_champagne_real_pain_phrases(sham_word, sham_word_override=overrides.get(sham_word)):\n        if s.lexicon.get(metadata[\"pain_word\"], 0) &lt; 0:\n            print(champagne_phrase)\n\n\nmedic for my real friends, real dick for my meh friends\nmetric for my real friends, real trick for my meh friends\nmetrics for my real friends, real tricks for my meh friends\nchampagnes for my real friends, real pains for my sham friends\nchampagne for my real friends, real pain for my sham friends\nchamois for my real friends, real woe for my sham friends\nmidrash for my real friends, real rash for my mid friends\n\n\n\n\n\nWhat pain words are excluded by the existing positive/negative methodology?\n\n\nCode\n\nfor sham_word in [\"faux\", \"sham\", \"mid\", \"meh\", \"bad\"]:\n    for champagne_phrase, metadata in find_champagne_real_pain_phrases(sham_word, sham_word_override=overrides.get(sham_word), filter_by_sentiment=False):\n        if not is_negative(metadata[\"pain_word\"], default=False) and \\\n           is_positive(metadata[\"candidate_champagne_compound_word\"], default=True):\n            print(champagne_phrase)\n    print()\n\n\nfocuses for my real friends, real kisses for my faux friends\nfocusing for my real friends, real kissing for my faux friends\nphotons for my real friends, real tonnes for my faux friends\nfocuses for my real friends, real kisses for my faux friends\nfocusing for my real friends, real kissing for my faux friends\n\nshamrock for my real friends, real roc for my sham friends\n\nmidwife for my real friends, real wife for my mid friends\nmidwives for my real friends, real wives for my mid friends\nmidsummer for my real friends, real summer for my mid friends\n\nmarried for my real friends, real read for my meh friends\nmenus for my real friends, real news for my meh friends\nmesquite for my real friends, real skeet for my meh friends\nmelons for my real friends, real lawns for my meh friends\nmelon for my real friends, real lawn for my meh friends\n\n\n\n\nIn particular, I like\n\nchamonix for my real friends, real money for my sham friends\nmenus for my real friends, real news for my meh friends\n\nbut they don’t quite fit the rubric (since neither money nor news is really negative.)\nThoughts? Improvements? Suggestions on more sham words I should plug in? Please send me an email, message me on Mastodon or Bluesky or open a Github issue."
  }
]